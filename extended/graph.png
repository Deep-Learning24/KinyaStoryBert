digraph {
	graph [size="321.75,321.75"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	1638912474000 [label="
 (1, 512, 768)" fillcolor=darkolivegreen1]
	1638912531696 [label=NativeLayerNormBackward0]
	1638912531840 -> 1638912531696
	1638912531840 [label=AddBackward0]
	1638912532032 -> 1638912531840
	1638912532032 [label=ViewBackward0]
	1638912532176 -> 1638912532032
	1638912532176 [label=AddmmBackward0]
	1638912532272 -> 1638912532176
	1638868478736 [label="bert.encoder.layer.11.output.dense.bias
 (768)" fillcolor=lightblue]
	1638868478736 -> 1638912532272
	1638912532272 [label=AccumulateGrad]
	1638912532224 -> 1638912532176
	1638912532224 [label=ViewBackward0]
	1638912532368 -> 1638912532224
	1638912532368 [label=GeluBackward0]
	1638912532560 -> 1638912532368
	1638912532560 [label=ViewBackward0]
	1638912532656 -> 1638912532560
	1638912532656 [label=AddmmBackward0]
	1638912532752 -> 1638912532656
	1638868478544 [label="bert.encoder.layer.11.intermediate.dense.bias
 (3072)" fillcolor=lightblue]
	1638868478544 -> 1638912532752
	1638912532752 [label=AccumulateGrad]
	1638912532704 -> 1638912532656
	1638912532704 [label=ViewBackward0]
	1638912531744 -> 1638912532704
	1638912531744 [label=NativeLayerNormBackward0]
	1638912532992 -> 1638912531744
	1638912532992 [label=AddBackward0]
	1638912533184 -> 1638912532992
	1638912533184 [label=ViewBackward0]
	1638912533328 -> 1638912533184
	1638912533328 [label=AddmmBackward0]
	1638912533424 -> 1638912533328
	1638868478160 [label="bert.encoder.layer.11.attention.output.dense.bias
 (768)" fillcolor=lightblue]
	1638868478160 -> 1638912533424
	1638912533424 [label=AccumulateGrad]
	1638912533376 -> 1638912533328
	1638912533376 [label=ViewBackward0]
	1638912533520 -> 1638912533376
	1638912533520 [label=ViewBackward0]
	1638912533712 -> 1638912533520
	1638912533712 [label=CloneBackward0]
	1638912533808 -> 1638912533712
	1638912533808 [label=PermuteBackward0]
	1638912533904 -> 1638912533808
	1638912533904 [label=UnsafeViewBackward0]
	1638912534000 -> 1638912533904
	1638912534000 [label=BmmBackward0]
	1638912534096 -> 1638912534000
	1638912534096 [label=ViewBackward0]
	1638912534240 -> 1638912534096
	1638912534240 [label=ExpandBackward0]
	1638912534336 -> 1638912534240
	1638912534336 [label=SoftmaxBackward0]
	1638912534432 -> 1638912534336
	1638912534432 [label=AddBackward0]
	1638912534528 -> 1638912534432
	1638912534528 [label=DivBackward0]
	1638912534624 -> 1638912534528
	1638912534624 [label=UnsafeViewBackward0]
	1638912534720 -> 1638912534624
	1638912534720 [label=BmmBackward0]
	1638912534816 -> 1638912534720
	1638912534816 [label=ReshapeAliasBackward0]
	1638912534960 -> 1638912534816
	1638912534960 [label=ExpandBackward0]
	1638912535056 -> 1638912534960
	1638912535056 [label=PermuteBackward0]
	1638912535152 -> 1638912535056
	1638912535152 [label=ViewBackward0]
	1638912535248 -> 1638912535152
	1638912535248 [label=ViewBackward0]
	1638912535344 -> 1638912535248
	1638912535344 [label=AddmmBackward0]
	1638912535440 -> 1638912535344
	1638868477584 [label="bert.encoder.layer.11.attention.self.query.bias
 (768)" fillcolor=lightblue]
	1638868477584 -> 1638912535440
	1638912535440 [label=AccumulateGrad]
	1638912535392 -> 1638912535344
	1638912535392 [label=ViewBackward0]
	1638912533136 -> 1638912535392
	1638912533136 [label=NativeLayerNormBackward0]
	1638912535680 -> 1638912533136
	1638912535680 [label=AddBackward0]
	1638912535872 -> 1638912535680
	1638912535872 [label=ViewBackward0]
	1638912536016 -> 1638912535872
	1638912536016 [label=AddmmBackward0]
	1638912536112 -> 1638912536016
	1638868477200 [label="bert.encoder.layer.10.output.dense.bias
 (768)" fillcolor=lightblue]
	1638868477200 -> 1638912536112
	1638912536112 [label=AccumulateGrad]
	1638912536064 -> 1638912536016
	1638912536064 [label=ViewBackward0]
	1638912536208 -> 1638912536064
	1638912536208 [label=GeluBackward0]
	1638912536400 -> 1638912536208
	1638912536400 [label=ViewBackward0]
	1638912536496 -> 1638912536400
	1638912536496 [label=AddmmBackward0]
	1638912536592 -> 1638912536496
	1638868477008 [label="bert.encoder.layer.10.intermediate.dense.bias
 (3072)" fillcolor=lightblue]
	1638868477008 -> 1638912536592
	1638912536592 [label=AccumulateGrad]
	1638912536544 -> 1638912536496
	1638912536544 [label=ViewBackward0]
	1638912535824 -> 1638912536544
	1638912535824 [label=NativeLayerNormBackward0]
	1638912536928 -> 1638912535824
	1638912536928 [label=AddBackward0]
	1638912537120 -> 1638912536928
	1638912537120 [label=ViewBackward0]
	1638912537264 -> 1638912537120
	1638912537264 [label=AddmmBackward0]
	1638912537360 -> 1638912537264
	1638868476624 [label="bert.encoder.layer.10.attention.output.dense.bias
 (768)" fillcolor=lightblue]
	1638868476624 -> 1638912537360
	1638912537360 [label=AccumulateGrad]
	1638912537312 -> 1638912537264
	1638912537312 [label=ViewBackward0]
	1638912537456 -> 1638912537312
	1638912537456 [label=ViewBackward0]
	1638912537744 -> 1638912537456
	1638912537744 [label=CloneBackward0]
	1638912537840 -> 1638912537744
	1638912537840 [label=PermuteBackward0]
	1638912537888 -> 1638912537840
	1638912537888 [label=UnsafeViewBackward0]
	1638912538032 -> 1638912537888
	1638912538032 [label=BmmBackward0]
	1638912538176 -> 1638912538032
	1638912538176 [label=ViewBackward0]
	1638912538416 -> 1638912538176
	1638912538416 [label=ExpandBackward0]
	1638912538464 -> 1638912538416
	1638912538464 [label=SoftmaxBackward0]
	1638912538608 -> 1638912538464
	1638912538608 [label=AddBackward0]
	1638912538752 -> 1638912538608
	1638912538752 [label=DivBackward0]
	1638912538944 -> 1638912538752
	1638912538944 [label=UnsafeViewBackward0]
	1638912539040 -> 1638912538944
	1638912539040 [label=BmmBackward0]
	1638912539088 -> 1638912539040
	1638912539088 [label=ReshapeAliasBackward0]
	1638912539328 -> 1638912539088
	1638912539328 [label=ExpandBackward0]
	1638912539376 -> 1638912539328
	1638912539376 [label=PermuteBackward0]
	1638912539520 -> 1638912539376
	1638912539520 [label=ViewBackward0]
	1638912539664 -> 1638912539520
	1638912539664 [label=ViewBackward0]
	1638912539808 -> 1638912539664
	1638912539808 [label=AddmmBackward0]
	1638912539952 -> 1638912539808
	1638868476048 [label="bert.encoder.layer.10.attention.self.query.bias
 (768)" fillcolor=lightblue]
	1638868476048 -> 1638912539952
	1638912539952 [label=AccumulateGrad]
	1638912539904 -> 1638912539808
	1638912539904 [label=ViewBackward0]
	1638912537072 -> 1638912539904
	1638912537072 [label=NativeLayerNormBackward0]
	1638912540384 -> 1638912537072
	1638912540384 [label=AddBackward0]
	1638912540576 -> 1638912540384
	1638912540576 [label=ViewBackward0]
	1638912540624 -> 1638912540576
	1638912540624 [label=AddmmBackward0]
	1638912639184 -> 1638912540624
	1638868475664 [label="bert.encoder.layer.9.output.dense.bias
 (768)" fillcolor=lightblue]
	1638868475664 -> 1638912639184
	1638912639184 [label=AccumulateGrad]
	1638912639136 -> 1638912540624
	1638912639136 [label=ViewBackward0]
	1638912639280 -> 1638912639136
	1638912639280 [label=GeluBackward0]
	1638912639568 -> 1638912639280
	1638912639568 [label=ViewBackward0]
	1638912639664 -> 1638912639568
	1638912639664 [label=AddmmBackward0]
	1638912639712 -> 1638912639664
	1638868475472 [label="bert.encoder.layer.9.intermediate.dense.bias
 (3072)" fillcolor=lightblue]
	1638868475472 -> 1638912639712
	1638912639712 [label=AccumulateGrad]
	1638912639472 -> 1638912639664
	1638912639472 [label=ViewBackward0]
	1638912540528 -> 1638912639472
	1638912540528 [label=NativeLayerNormBackward0]
	1638912640144 -> 1638912540528
	1638912640144 [label=AddBackward0]
	1638912640336 -> 1638912640144
	1638912640336 [label=ViewBackward0]
	1638912640480 -> 1638912640336
	1638912640480 [label=AddmmBackward0]
	1638912640576 -> 1638912640480
	1638868475088 [label="bert.encoder.layer.9.attention.output.dense.bias
 (768)" fillcolor=lightblue]
	1638868475088 -> 1638912640576
	1638912640576 [label=AccumulateGrad]
	1638912640528 -> 1638912640480
	1638912640528 [label=ViewBackward0]
	1638912640672 -> 1638912640528
	1638912640672 [label=ViewBackward0]
	1638912640960 -> 1638912640672
	1638912640960 [label=CloneBackward0]
	1638912641056 -> 1638912640960
	1638912641056 [label=PermuteBackward0]
	1638912641104 -> 1638912641056
	1638912641104 [label=UnsafeViewBackward0]
	1638912641248 -> 1638912641104
	1638912641248 [label=BmmBackward0]
	1638912641392 -> 1638912641248
	1638912641392 [label=ViewBackward0]
	1638912641632 -> 1638912641392
	1638912641632 [label=ExpandBackward0]
	1638912641680 -> 1638912641632
	1638912641680 [label=SoftmaxBackward0]
	1638912641824 -> 1638912641680
	1638912641824 [label=AddBackward0]
	1638912641968 -> 1638912641824
	1638912641968 [label=DivBackward0]
	1638912642160 -> 1638912641968
	1638912642160 [label=UnsafeViewBackward0]
	1638912642256 -> 1638912642160
	1638912642256 [label=BmmBackward0]
	1638912642304 -> 1638912642256
	1638912642304 [label=ReshapeAliasBackward0]
	1638912642544 -> 1638912642304
	1638912642544 [label=ExpandBackward0]
	1638912642592 -> 1638912642544
	1638912642592 [label=PermuteBackward0]
	1638912642736 -> 1638912642592
	1638912642736 [label=ViewBackward0]
	1638912642880 -> 1638912642736
	1638912642880 [label=ViewBackward0]
	1638912643024 -> 1638912642880
	1638912643024 [label=AddmmBackward0]
	1638912643168 -> 1638912643024
	1638868474512 [label="bert.encoder.layer.9.attention.self.query.bias
 (768)" fillcolor=lightblue]
	1638868474512 -> 1638912643168
	1638912643168 [label=AccumulateGrad]
	1638912643120 -> 1638912643024
	1638912643120 [label=ViewBackward0]
	1638912640288 -> 1638912643120
	1638912640288 [label=NativeLayerNormBackward0]
	1638912643600 -> 1638912640288
	1638912643600 [label=AddBackward0]
	1638912643792 -> 1638912643600
	1638912643792 [label=ViewBackward0]
	1638912643936 -> 1638912643792
	1638912643936 [label=AddmmBackward0]
	1638912644032 -> 1638912643936
	1638868474128 [label="bert.encoder.layer.8.output.dense.bias
 (768)" fillcolor=lightblue]
	1638868474128 -> 1638912644032
	1638912644032 [label=AccumulateGrad]
	1638912643984 -> 1638912643936
	1638912643984 [label=ViewBackward0]
	1638912644128 -> 1638912643984
	1638912644128 [label=GeluBackward0]
	1638912644416 -> 1638912644128
	1638912644416 [label=ViewBackward0]
	1638912644512 -> 1638912644416
	1638912644512 [label=AddmmBackward0]
	1638912644560 -> 1638912644512
	1638868473936 [label="bert.encoder.layer.8.intermediate.dense.bias
 (3072)" fillcolor=lightblue]
	1638868473936 -> 1638912644560
	1638912644560 [label=AccumulateGrad]
	1638912644320 -> 1638912644512
	1638912644320 [label=ViewBackward0]
	1638912643744 -> 1638912644320
	1638912643744 [label=NativeLayerNormBackward0]
	1638912644992 -> 1638912643744
	1638912644992 [label=AddBackward0]
	1638912645184 -> 1638912644992
	1638912645184 [label=ViewBackward0]
	1638912645328 -> 1638912645184
	1638912645328 [label=AddmmBackward0]
	1638912645424 -> 1638912645328
	1638868473552 [label="bert.encoder.layer.8.attention.output.dense.bias
 (768)" fillcolor=lightblue]
	1638868473552 -> 1638912645424
	1638912645424 [label=AccumulateGrad]
	1638912645376 -> 1638912645328
	1638912645376 [label=ViewBackward0]
	1638912645520 -> 1638912645376
	1638912645520 [label=ViewBackward0]
	1638912645808 -> 1638912645520
	1638912645808 [label=CloneBackward0]
	1638912645904 -> 1638912645808
	1638912645904 [label=PermuteBackward0]
	1638912645952 -> 1638912645904
	1638912645952 [label=UnsafeViewBackward0]
	1638912646096 -> 1638912645952
	1638912646096 [label=BmmBackward0]
	1638912646240 -> 1638912646096
	1638912646240 [label=ViewBackward0]
	1638912646480 -> 1638912646240
	1638912646480 [label=ExpandBackward0]
	1638912646528 -> 1638912646480
	1638912646528 [label=SoftmaxBackward0]
	1638912646672 -> 1638912646528
	1638912646672 [label=AddBackward0]
	1638912646816 -> 1638912646672
	1638912646816 [label=DivBackward0]
	1638912647008 -> 1638912646816
	1638912647008 [label=UnsafeViewBackward0]
	1638912647104 -> 1638912647008
	1638912647104 [label=BmmBackward0]
	1638912647152 -> 1638912647104
	1638912647152 [label=ReshapeAliasBackward0]
	1638912647392 -> 1638912647152
	1638912647392 [label=ExpandBackward0]
	1638912647440 -> 1638912647392
	1638912647440 [label=PermuteBackward0]
	1638912647584 -> 1638912647440
	1638912647584 [label=ViewBackward0]
	1638912647728 -> 1638912647584
	1638912647728 [label=ViewBackward0]
	1638912647872 -> 1638912647728
	1638912647872 [label=AddmmBackward0]
	1638912648016 -> 1638912647872
	1638868472976 [label="bert.encoder.layer.8.attention.self.query.bias
 (768)" fillcolor=lightblue]
	1638868472976 -> 1638912648016
	1638912648016 [label=AccumulateGrad]
	1638912647968 -> 1638912647872
	1638912647968 [label=ViewBackward0]
	1638912645136 -> 1638912647968
	1638912645136 [label=NativeLayerNormBackward0]
	1638912648448 -> 1638912645136
	1638912648448 [label=AddBackward0]
	1638912648640 -> 1638912648448
	1638912648640 [label=ViewBackward0]
	1638912648784 -> 1638912648640
	1638912648784 [label=AddmmBackward0]
	1638912648880 -> 1638912648784
	1638868472592 [label="bert.encoder.layer.7.output.dense.bias
 (768)" fillcolor=lightblue]
	1638868472592 -> 1638912648880
	1638912648880 [label=AccumulateGrad]
	1638912648832 -> 1638912648784
	1638912648832 [label=ViewBackward0]
	1638912648976 -> 1638912648832
	1638912648976 [label=GeluBackward0]
	1638912649264 -> 1638912648976
	1638912649264 [label=ViewBackward0]
	1638912649360 -> 1638912649264
	1638912649360 [label=AddmmBackward0]
	1638912649408 -> 1638912649360
	1638868472400 [label="bert.encoder.layer.7.intermediate.dense.bias
 (3072)" fillcolor=lightblue]
	1638868472400 -> 1638912649408
	1638912649408 [label=AccumulateGrad]
	1638912649168 -> 1638912649360
	1638912649168 [label=ViewBackward0]
	1638912648592 -> 1638912649168
	1638912648592 [label=NativeLayerNormBackward0]
	1638912649840 -> 1638912648592
	1638912649840 [label=AddBackward0]
	1638912650032 -> 1638912649840
	1638912650032 [label=ViewBackward0]
	1638912650176 -> 1638912650032
	1638912650176 [label=AddmmBackward0]
	1638912650272 -> 1638912650176
	1638868472016 [label="bert.encoder.layer.7.attention.output.dense.bias
 (768)" fillcolor=lightblue]
	1638868472016 -> 1638912650272
	1638912650272 [label=AccumulateGrad]
	1638912650224 -> 1638912650176
	1638912650224 [label=ViewBackward0]
	1638912650368 -> 1638912650224
	1638912650368 [label=ViewBackward0]
	1638912650656 -> 1638912650368
	1638912650656 [label=CloneBackward0]
	1638912650752 -> 1638912650656
	1638912650752 [label=PermuteBackward0]
	1638912650800 -> 1638912650752
	1638912650800 [label=UnsafeViewBackward0]
	1638912650944 -> 1638912650800
	1638912650944 [label=BmmBackward0]
	1638912651088 -> 1638912650944
	1638912651088 [label=ViewBackward0]
	1638912651328 -> 1638912651088
	1638912651328 [label=ExpandBackward0]
	1638912651376 -> 1638912651328
	1638912651376 [label=SoftmaxBackward0]
	1638912651520 -> 1638912651376
	1638912651520 [label=AddBackward0]
	1638912651664 -> 1638912651520
	1638912651664 [label=DivBackward0]
	1638912651856 -> 1638912651664
	1638912651856 [label=UnsafeViewBackward0]
	1638912651952 -> 1638912651856
	1638912651952 [label=BmmBackward0]
	1638912652000 -> 1638912651952
	1638912652000 [label=ReshapeAliasBackward0]
	1638912652240 -> 1638912652000
	1638912652240 [label=ExpandBackward0]
	1638912652288 -> 1638912652240
	1638912652288 [label=PermuteBackward0]
	1638912652432 -> 1638912652288
	1638912652432 [label=ViewBackward0]
	1638912652576 -> 1638912652432
	1638912652576 [label=ViewBackward0]
	1638912652720 -> 1638912652576
	1638912652720 [label=AddmmBackward0]
	1638912652864 -> 1638912652720
	1638868471440 [label="bert.encoder.layer.7.attention.self.query.bias
 (768)" fillcolor=lightblue]
	1638868471440 -> 1638912652864
	1638912652864 [label=AccumulateGrad]
	1638912652816 -> 1638912652720
	1638912652816 [label=ViewBackward0]
	1638912649984 -> 1638912652816
	1638912649984 [label=NativeLayerNormBackward0]
	1638912653296 -> 1638912649984
	1638912653296 [label=AddBackward0]
	1638912653488 -> 1638912653296
	1638912653488 [label=ViewBackward0]
	1638912653632 -> 1638912653488
	1638912653632 [label=AddmmBackward0]
	1638912653728 -> 1638912653632
	1638868471056 [label="bert.encoder.layer.6.output.dense.bias
 (768)" fillcolor=lightblue]
	1638868471056 -> 1638912653728
	1638912653728 [label=AccumulateGrad]
	1638912653680 -> 1638912653632
	1638912653680 [label=ViewBackward0]
	1638912653824 -> 1638912653680
	1638912653824 [label=GeluBackward0]
	1638912654112 -> 1638912653824
	1638912654112 [label=ViewBackward0]
	1638912654208 -> 1638912654112
	1638912654208 [label=AddmmBackward0]
	1638912654256 -> 1638912654208
	1638868470864 [label="bert.encoder.layer.6.intermediate.dense.bias
 (3072)" fillcolor=lightblue]
	1638868470864 -> 1638912654256
	1638912654256 [label=AccumulateGrad]
	1638912654016 -> 1638912654208
	1638912654016 [label=ViewBackward0]
	1638912653440 -> 1638912654016
	1638912653440 [label=NativeLayerNormBackward0]
	1638912654688 -> 1638912653440
	1638912654688 [label=AddBackward0]
	1638912654880 -> 1638912654688
	1638912654880 [label=ViewBackward0]
	1638912655024 -> 1638912654880
	1638912655024 [label=AddmmBackward0]
	1638912655120 -> 1638912655024
	1638868470480 [label="bert.encoder.layer.6.attention.output.dense.bias
 (768)" fillcolor=lightblue]
	1638868470480 -> 1638912655120
	1638912655120 [label=AccumulateGrad]
	1638912655072 -> 1638912655024
	1638912655072 [label=ViewBackward0]
	1638912655216 -> 1638912655072
	1638912655216 [label=ViewBackward0]
	1639163298000 -> 1638912655216
	1639163298000 [label=CloneBackward0]
	1639163298096 -> 1639163298000
	1639163298096 [label=PermuteBackward0]
	1639163298144 -> 1639163298096
	1639163298144 [label=UnsafeViewBackward0]
	1639163298288 -> 1639163298144
	1639163298288 [label=BmmBackward0]
	1639163298432 -> 1639163298288
	1639163298432 [label=ViewBackward0]
	1639163298672 -> 1639163298432
	1639163298672 [label=ExpandBackward0]
	1639163298720 -> 1639163298672
	1639163298720 [label=SoftmaxBackward0]
	1639163298864 -> 1639163298720
	1639163298864 [label=AddBackward0]
	1639163299008 -> 1639163298864
	1639163299008 [label=DivBackward0]
	1639163299200 -> 1639163299008
	1639163299200 [label=UnsafeViewBackward0]
	1639163299296 -> 1639163299200
	1639163299296 [label=BmmBackward0]
	1639163299344 -> 1639163299296
	1639163299344 [label=ReshapeAliasBackward0]
	1639163299584 -> 1639163299344
	1639163299584 [label=ExpandBackward0]
	1639163299632 -> 1639163299584
	1639163299632 [label=PermuteBackward0]
	1639163299776 -> 1639163299632
	1639163299776 [label=ViewBackward0]
	1639163299920 -> 1639163299776
	1639163299920 [label=ViewBackward0]
	1639163300064 -> 1639163299920
	1639163300064 [label=AddmmBackward0]
	1639163300208 -> 1639163300064
	1638868469904 [label="bert.encoder.layer.6.attention.self.query.bias
 (768)" fillcolor=lightblue]
	1638868469904 -> 1639163300208
	1639163300208 [label=AccumulateGrad]
	1639163300160 -> 1639163300064
	1639163300160 [label=ViewBackward0]
	1638912654832 -> 1639163300160
	1638912654832 [label=NativeLayerNormBackward0]
	1639163300640 -> 1638912654832
	1639163300640 [label=AddBackward0]
	1639163300832 -> 1639163300640
	1639163300832 [label=ViewBackward0]
	1639163300976 -> 1639163300832
	1639163300976 [label=AddmmBackward0]
	1639163301072 -> 1639163300976
	1638868469520 [label="bert.encoder.layer.5.output.dense.bias
 (768)" fillcolor=lightblue]
	1638868469520 -> 1639163301072
	1639163301072 [label=AccumulateGrad]
	1639163301024 -> 1639163300976
	1639163301024 [label=ViewBackward0]
	1639163301168 -> 1639163301024
	1639163301168 [label=GeluBackward0]
	1639163301456 -> 1639163301168
	1639163301456 [label=ViewBackward0]
	1639163301552 -> 1639163301456
	1639163301552 [label=AddmmBackward0]
	1639163301600 -> 1639163301552
	1638868469328 [label="bert.encoder.layer.5.intermediate.dense.bias
 (3072)" fillcolor=lightblue]
	1638868469328 -> 1639163301600
	1639163301600 [label=AccumulateGrad]
	1639163301360 -> 1639163301552
	1639163301360 [label=ViewBackward0]
	1639163300784 -> 1639163301360
	1639163300784 [label=NativeLayerNormBackward0]
	1639163302032 -> 1639163300784
	1639163302032 [label=AddBackward0]
	1639163302224 -> 1639163302032
	1639163302224 [label=ViewBackward0]
	1639163302368 -> 1639163302224
	1639163302368 [label=AddmmBackward0]
	1639163302464 -> 1639163302368
	1638868468944 [label="bert.encoder.layer.5.attention.output.dense.bias
 (768)" fillcolor=lightblue]
	1638868468944 -> 1639163302464
	1639163302464 [label=AccumulateGrad]
	1639163302416 -> 1639163302368
	1639163302416 [label=ViewBackward0]
	1639163302560 -> 1639163302416
	1639163302560 [label=ViewBackward0]
	1639163302848 -> 1639163302560
	1639163302848 [label=CloneBackward0]
	1639163302944 -> 1639163302848
	1639163302944 [label=PermuteBackward0]
	1639163302992 -> 1639163302944
	1639163302992 [label=UnsafeViewBackward0]
	1639163303136 -> 1639163302992
	1639163303136 [label=BmmBackward0]
	1639163303280 -> 1639163303136
	1639163303280 [label=ViewBackward0]
	1639163303520 -> 1639163303280
	1639163303520 [label=ExpandBackward0]
	1639163303568 -> 1639163303520
	1639163303568 [label=SoftmaxBackward0]
	1639163303712 -> 1639163303568
	1639163303712 [label=AddBackward0]
	1639163303856 -> 1639163303712
	1639163303856 [label=DivBackward0]
	1639163304048 -> 1639163303856
	1639163304048 [label=UnsafeViewBackward0]
	1639163304144 -> 1639163304048
	1639163304144 [label=BmmBackward0]
	1639163304192 -> 1639163304144
	1639163304192 [label=ReshapeAliasBackward0]
	1639163304432 -> 1639163304192
	1639163304432 [label=ExpandBackward0]
	1639163304480 -> 1639163304432
	1639163304480 [label=PermuteBackward0]
	1639163304624 -> 1639163304480
	1639163304624 [label=ViewBackward0]
	1639163304768 -> 1639163304624
	1639163304768 [label=ViewBackward0]
	1639163304912 -> 1639163304768
	1639163304912 [label=AddmmBackward0]
	1639163305056 -> 1639163304912
	1638868468368 [label="bert.encoder.layer.5.attention.self.query.bias
 (768)" fillcolor=lightblue]
	1638868468368 -> 1639163305056
	1639163305056 [label=AccumulateGrad]
	1639163305008 -> 1639163304912
	1639163305008 [label=ViewBackward0]
	1639163302176 -> 1639163305008
	1639163302176 [label=NativeLayerNormBackward0]
	1639163305488 -> 1639163302176
	1639163305488 [label=AddBackward0]
	1639163305680 -> 1639163305488
	1639163305680 [label=ViewBackward0]
	1639163305824 -> 1639163305680
	1639163305824 [label=AddmmBackward0]
	1639163305920 -> 1639163305824
	1638868467984 [label="bert.encoder.layer.4.output.dense.bias
 (768)" fillcolor=lightblue]
	1638868467984 -> 1639163305920
	1639163305920 [label=AccumulateGrad]
	1639163305872 -> 1639163305824
	1639163305872 [label=ViewBackward0]
	1639163306016 -> 1639163305872
	1639163306016 [label=GeluBackward0]
	1639163306304 -> 1639163306016
	1639163306304 [label=ViewBackward0]
	1639163306400 -> 1639163306304
	1639163306400 [label=AddmmBackward0]
	1639163306448 -> 1639163306400
	1638868467792 [label="bert.encoder.layer.4.intermediate.dense.bias
 (3072)" fillcolor=lightblue]
	1638868467792 -> 1639163306448
	1639163306448 [label=AccumulateGrad]
	1639163306208 -> 1639163306400
	1639163306208 [label=ViewBackward0]
	1639163305632 -> 1639163306208
	1639163305632 [label=NativeLayerNormBackward0]
	1639163306880 -> 1639163305632
	1639163306880 [label=AddBackward0]
	1639163307072 -> 1639163306880
	1639163307072 [label=ViewBackward0]
	1639163307216 -> 1639163307072
	1639163307216 [label=AddmmBackward0]
	1639163307312 -> 1639163307216
	1638868221584 [label="bert.encoder.layer.4.attention.output.dense.bias
 (768)" fillcolor=lightblue]
	1638868221584 -> 1639163307312
	1639163307312 [label=AccumulateGrad]
	1639163307264 -> 1639163307216
	1639163307264 [label=ViewBackward0]
	1639163307408 -> 1639163307264
	1639163307408 [label=ViewBackward0]
	1639163307696 -> 1639163307408
	1639163307696 [label=CloneBackward0]
	1639163307792 -> 1639163307696
	1639163307792 [label=PermuteBackward0]
	1639163307840 -> 1639163307792
	1639163307840 [label=UnsafeViewBackward0]
	1639163307984 -> 1639163307840
	1639163307984 [label=BmmBackward0]
	1639163308128 -> 1639163307984
	1639163308128 [label=ViewBackward0]
	1639163308368 -> 1639163308128
	1639163308368 [label=ExpandBackward0]
	1639163308416 -> 1639163308368
	1639163308416 [label=SoftmaxBackward0]
	1639163308560 -> 1639163308416
	1639163308560 [label=AddBackward0]
	1639163308704 -> 1639163308560
	1639163308704 [label=DivBackward0]
	1639163308896 -> 1639163308704
	1639163308896 [label=UnsafeViewBackward0]
	1639163308992 -> 1639163308896
	1639163308992 [label=BmmBackward0]
	1639163309040 -> 1639163308992
	1639163309040 [label=ReshapeAliasBackward0]
	1639163309280 -> 1639163309040
	1639163309280 [label=ExpandBackward0]
	1639163309328 -> 1639163309280
	1639163309328 [label=PermuteBackward0]
	1639163309472 -> 1639163309328
	1639163309472 [label=ViewBackward0]
	1639163309616 -> 1639163309472
	1639163309616 [label=ViewBackward0]
	1639163309760 -> 1639163309616
	1639163309760 [label=AddmmBackward0]
	1639163309904 -> 1639163309760
	1638868221008 [label="bert.encoder.layer.4.attention.self.query.bias
 (768)" fillcolor=lightblue]
	1638868221008 -> 1639163309904
	1639163309904 [label=AccumulateGrad]
	1639163309856 -> 1639163309760
	1639163309856 [label=ViewBackward0]
	1639163307024 -> 1639163309856
	1639163307024 [label=NativeLayerNormBackward0]
	1639163310336 -> 1639163307024
	1639163310336 [label=AddBackward0]
	1639163310528 -> 1639163310336
	1639163310528 [label=ViewBackward0]
	1639163310672 -> 1639163310528
	1639163310672 [label=AddmmBackward0]
	1639163310768 -> 1639163310672
	1638868220624 [label="bert.encoder.layer.3.output.dense.bias
 (768)" fillcolor=lightblue]
	1638868220624 -> 1639163310768
	1639163310768 [label=AccumulateGrad]
	1639163310720 -> 1639163310672
	1639163310720 [label=ViewBackward0]
	1639163310864 -> 1639163310720
	1639163310864 [label=GeluBackward0]
	1639163311152 -> 1639163310864
	1639163311152 [label=ViewBackward0]
	1639163311248 -> 1639163311152
	1639163311248 [label=AddmmBackward0]
	1639163311296 -> 1639163311248
	1638868220432 [label="bert.encoder.layer.3.intermediate.dense.bias
 (3072)" fillcolor=lightblue]
	1638868220432 -> 1639163311296
	1639163311296 [label=AccumulateGrad]
	1639163311056 -> 1639163311248
	1639163311056 [label=ViewBackward0]
	1639163310480 -> 1639163311056
	1639163310480 [label=NativeLayerNormBackward0]
	1639163311728 -> 1639163310480
	1639163311728 [label=AddBackward0]
	1639163311920 -> 1639163311728
	1639163311920 [label=ViewBackward0]
	1639163312064 -> 1639163311920
	1639163312064 [label=AddmmBackward0]
	1639163312160 -> 1639163312064
	1638868220048 [label="bert.encoder.layer.3.attention.output.dense.bias
 (768)" fillcolor=lightblue]
	1638868220048 -> 1639163312160
	1639163312160 [label=AccumulateGrad]
	1639163312112 -> 1639163312064
	1639163312112 [label=ViewBackward0]
	1639163312256 -> 1639163312112
	1639163312256 [label=ViewBackward0]
	1639163312544 -> 1639163312256
	1639163312544 [label=CloneBackward0]
	1639163312640 -> 1639163312544
	1639163312640 [label=PermuteBackward0]
	1639163312688 -> 1639163312640
	1639163312688 [label=UnsafeViewBackward0]
	1639163312832 -> 1639163312688
	1639163312832 [label=BmmBackward0]
	1639163312976 -> 1639163312832
	1639163312976 [label=ViewBackward0]
	1639163313216 -> 1639163312976
	1639163313216 [label=ExpandBackward0]
	1639163313264 -> 1639163313216
	1639163313264 [label=SoftmaxBackward0]
	1639163313408 -> 1639163313264
	1639163313408 [label=AddBackward0]
	1639163313552 -> 1639163313408
	1639163313552 [label=DivBackward0]
	1639163313744 -> 1639163313552
	1639163313744 [label=UnsafeViewBackward0]
	1639163313840 -> 1639163313744
	1639163313840 [label=BmmBackward0]
	1639163313888 -> 1639163313840
	1639163313888 [label=ReshapeAliasBackward0]
	1639163314128 -> 1639163313888
	1639163314128 [label=ExpandBackward0]
	1639163330672 -> 1639163314128
	1639163330672 [label=PermuteBackward0]
	1639163330768 -> 1639163330672
	1639163330768 [label=ViewBackward0]
	1639163330912 -> 1639163330768
	1639163330912 [label=ViewBackward0]
	1639163331056 -> 1639163330912
	1639163331056 [label=AddmmBackward0]
	1639163331200 -> 1639163331056
	1638868219472 [label="bert.encoder.layer.3.attention.self.query.bias
 (768)" fillcolor=lightblue]
	1638868219472 -> 1639163331200
	1639163331200 [label=AccumulateGrad]
	1639163331152 -> 1639163331056
	1639163331152 [label=ViewBackward0]
	1639163311872 -> 1639163331152
	1639163311872 [label=NativeLayerNormBackward0]
	1639163331632 -> 1639163311872
	1639163331632 [label=AddBackward0]
	1639163331824 -> 1639163331632
	1639163331824 [label=ViewBackward0]
	1639163331968 -> 1639163331824
	1639163331968 [label=AddmmBackward0]
	1639163332064 -> 1639163331968
	1638868219088 [label="bert.encoder.layer.2.output.dense.bias
 (768)" fillcolor=lightblue]
	1638868219088 -> 1639163332064
	1639163332064 [label=AccumulateGrad]
	1639163332016 -> 1639163331968
	1639163332016 [label=ViewBackward0]
	1639163332160 -> 1639163332016
	1639163332160 [label=GeluBackward0]
	1639163332448 -> 1639163332160
	1639163332448 [label=ViewBackward0]
	1639163332544 -> 1639163332448
	1639163332544 [label=AddmmBackward0]
	1639163332592 -> 1639163332544
	1638868218896 [label="bert.encoder.layer.2.intermediate.dense.bias
 (3072)" fillcolor=lightblue]
	1638868218896 -> 1639163332592
	1639163332592 [label=AccumulateGrad]
	1639163332352 -> 1639163332544
	1639163332352 [label=ViewBackward0]
	1639163331776 -> 1639163332352
	1639163331776 [label=NativeLayerNormBackward0]
	1639163333024 -> 1639163331776
	1639163333024 [label=AddBackward0]
	1639163333216 -> 1639163333024
	1639163333216 [label=ViewBackward0]
	1639163333360 -> 1639163333216
	1639163333360 [label=AddmmBackward0]
	1639163333456 -> 1639163333360
	1638868218512 [label="bert.encoder.layer.2.attention.output.dense.bias
 (768)" fillcolor=lightblue]
	1638868218512 -> 1639163333456
	1639163333456 [label=AccumulateGrad]
	1639163333408 -> 1639163333360
	1639163333408 [label=ViewBackward0]
	1639163333552 -> 1639163333408
	1639163333552 [label=ViewBackward0]
	1639163333840 -> 1639163333552
	1639163333840 [label=CloneBackward0]
	1639163333936 -> 1639163333840
	1639163333936 [label=PermuteBackward0]
	1639163333984 -> 1639163333936
	1639163333984 [label=UnsafeViewBackward0]
	1639163334128 -> 1639163333984
	1639163334128 [label=BmmBackward0]
	1639163334272 -> 1639163334128
	1639163334272 [label=ViewBackward0]
	1639163334512 -> 1639163334272
	1639163334512 [label=ExpandBackward0]
	1639163334560 -> 1639163334512
	1639163334560 [label=SoftmaxBackward0]
	1639163334704 -> 1639163334560
	1639163334704 [label=AddBackward0]
	1639163334848 -> 1639163334704
	1639163334848 [label=DivBackward0]
	1639163335040 -> 1639163334848
	1639163335040 [label=UnsafeViewBackward0]
	1639163335136 -> 1639163335040
	1639163335136 [label=BmmBackward0]
	1639163335184 -> 1639163335136
	1639163335184 [label=ReshapeAliasBackward0]
	1639163335424 -> 1639163335184
	1639163335424 [label=ExpandBackward0]
	1639163335472 -> 1639163335424
	1639163335472 [label=PermuteBackward0]
	1639163335616 -> 1639163335472
	1639163335616 [label=ViewBackward0]
	1639163335760 -> 1639163335616
	1639163335760 [label=ViewBackward0]
	1639163335904 -> 1639163335760
	1639163335904 [label=AddmmBackward0]
	1639163336048 -> 1639163335904
	1638868217936 [label="bert.encoder.layer.2.attention.self.query.bias
 (768)" fillcolor=lightblue]
	1638868217936 -> 1639163336048
	1639163336048 [label=AccumulateGrad]
	1639163336000 -> 1639163335904
	1639163336000 [label=ViewBackward0]
	1639163333168 -> 1639163336000
	1639163333168 [label=NativeLayerNormBackward0]
	1639163336480 -> 1639163333168
	1639163336480 [label=AddBackward0]
	1639163336672 -> 1639163336480
	1639163336672 [label=ViewBackward0]
	1639163336816 -> 1639163336672
	1639163336816 [label=AddmmBackward0]
	1639163336912 -> 1639163336816
	1638868217552 [label="bert.encoder.layer.1.output.dense.bias
 (768)" fillcolor=lightblue]
	1638868217552 -> 1639163336912
	1639163336912 [label=AccumulateGrad]
	1639163336864 -> 1639163336816
	1639163336864 [label=ViewBackward0]
	1639163337008 -> 1639163336864
	1639163337008 [label=GeluBackward0]
	1639163337296 -> 1639163337008
	1639163337296 [label=ViewBackward0]
	1639163337392 -> 1639163337296
	1639163337392 [label=AddmmBackward0]
	1639163337440 -> 1639163337392
	1638868217360 [label="bert.encoder.layer.1.intermediate.dense.bias
 (3072)" fillcolor=lightblue]
	1638868217360 -> 1639163337440
	1639163337440 [label=AccumulateGrad]
	1639163337200 -> 1639163337392
	1639163337200 [label=ViewBackward0]
	1639163336624 -> 1639163337200
	1639163336624 [label=NativeLayerNormBackward0]
	1639163337872 -> 1639163336624
	1639163337872 [label=AddBackward0]
	1639163338064 -> 1639163337872
	1639163338064 [label=ViewBackward0]
	1639163338208 -> 1639163338064
	1639163338208 [label=AddmmBackward0]
	1639163338304 -> 1639163338208
	1638868216976 [label="bert.encoder.layer.1.attention.output.dense.bias
 (768)" fillcolor=lightblue]
	1638868216976 -> 1639163338304
	1639163338304 [label=AccumulateGrad]
	1639163338256 -> 1639163338208
	1639163338256 [label=ViewBackward0]
	1639163338400 -> 1639163338256
	1639163338400 [label=ViewBackward0]
	1639163338688 -> 1639163338400
	1639163338688 [label=CloneBackward0]
	1639163338784 -> 1639163338688
	1639163338784 [label=PermuteBackward0]
	1639163338832 -> 1639163338784
	1639163338832 [label=UnsafeViewBackward0]
	1639163338976 -> 1639163338832
	1639163338976 [label=BmmBackward0]
	1639163339120 -> 1639163338976
	1639163339120 [label=ViewBackward0]
	1639163339360 -> 1639163339120
	1639163339360 [label=ExpandBackward0]
	1639163339408 -> 1639163339360
	1639163339408 [label=SoftmaxBackward0]
	1639163339552 -> 1639163339408
	1639163339552 [label=AddBackward0]
	1639163339696 -> 1639163339552
	1639163339696 [label=DivBackward0]
	1639163339888 -> 1639163339696
	1639163339888 [label=UnsafeViewBackward0]
	1639163339984 -> 1639163339888
	1639163339984 [label=BmmBackward0]
	1639163340032 -> 1639163339984
	1639163340032 [label=ReshapeAliasBackward0]
	1639163340272 -> 1639163340032
	1639163340272 [label=ExpandBackward0]
	1639163340320 -> 1639163340272
	1639163340320 [label=PermuteBackward0]
	1639163340464 -> 1639163340320
	1639163340464 [label=ViewBackward0]
	1639163340608 -> 1639163340464
	1639163340608 [label=ViewBackward0]
	1639163340752 -> 1639163340608
	1639163340752 [label=AddmmBackward0]
	1639163340896 -> 1639163340752
	1638868216400 [label="bert.encoder.layer.1.attention.self.query.bias
 (768)" fillcolor=lightblue]
	1638868216400 -> 1639163340896
	1639163340896 [label=AccumulateGrad]
	1639163340848 -> 1639163340752
	1639163340848 [label=ViewBackward0]
	1639163338016 -> 1639163340848
	1639163338016 [label=NativeLayerNormBackward0]
	1639163341328 -> 1639163338016
	1639163341328 [label=AddBackward0]
	1639163341520 -> 1639163341328
	1639163341520 [label=ViewBackward0]
	1639163341664 -> 1639163341520
	1639163341664 [label=AddmmBackward0]
	1639163341760 -> 1639163341664
	1638868216016 [label="bert.encoder.layer.0.output.dense.bias
 (768)" fillcolor=lightblue]
	1638868216016 -> 1639163341760
	1639163341760 [label=AccumulateGrad]
	1639163341712 -> 1639163341664
	1639163341712 [label=ViewBackward0]
	1639163341856 -> 1639163341712
	1639163341856 [label=GeluBackward0]
	1639163342144 -> 1639163341856
	1639163342144 [label=ViewBackward0]
	1639163342240 -> 1639163342144
	1639163342240 [label=AddmmBackward0]
	1639163342288 -> 1639163342240
	1638868215824 [label="bert.encoder.layer.0.intermediate.dense.bias
 (3072)" fillcolor=lightblue]
	1638868215824 -> 1639163342288
	1639163342288 [label=AccumulateGrad]
	1639163342048 -> 1639163342240
	1639163342048 [label=ViewBackward0]
	1639163341472 -> 1639163342048
	1639163341472 [label=NativeLayerNormBackward0]
	1639163342720 -> 1639163341472
	1639163342720 [label=AddBackward0]
	1639163342912 -> 1639163342720
	1639163342912 [label=ViewBackward0]
	1639163343056 -> 1639163342912
	1639163343056 [label=AddmmBackward0]
	1639163343152 -> 1639163343056
	1638868215440 [label="bert.encoder.layer.0.attention.output.dense.bias
 (768)" fillcolor=lightblue]
	1638868215440 -> 1639163343152
	1639163343152 [label=AccumulateGrad]
	1639163343104 -> 1639163343056
	1639163343104 [label=ViewBackward0]
	1639163343248 -> 1639163343104
	1639163343248 [label=ViewBackward0]
	1639163343536 -> 1639163343248
	1639163343536 [label=CloneBackward0]
	1639163343632 -> 1639163343536
	1639163343632 [label=PermuteBackward0]
	1639163343680 -> 1639163343632
	1639163343680 [label=UnsafeViewBackward0]
	1639163343824 -> 1639163343680
	1639163343824 [label=BmmBackward0]
	1639163343968 -> 1639163343824
	1639163343968 [label=ViewBackward0]
	1639163344208 -> 1639163343968
	1639163344208 [label=ExpandBackward0]
	1639163344256 -> 1639163344208
	1639163344256 [label=SoftmaxBackward0]
	1639163344400 -> 1639163344256
	1639163344400 [label=AddBackward0]
	1639163344544 -> 1639163344400
	1639163344544 [label=DivBackward0]
	1639163344736 -> 1639163344544
	1639163344736 [label=UnsafeViewBackward0]
	1639163344832 -> 1639163344736
	1639163344832 [label=BmmBackward0]
	1639163344880 -> 1639163344832
	1639163344880 [label=ReshapeAliasBackward0]
	1639163345120 -> 1639163344880
	1639163345120 [label=ExpandBackward0]
	1639163345168 -> 1639163345120
	1639163345168 [label=PermuteBackward0]
	1639163345312 -> 1639163345168
	1639163345312 [label=ViewBackward0]
	1639163345456 -> 1639163345312
	1639163345456 [label=ViewBackward0]
	1639163345600 -> 1639163345456
	1639163345600 [label=AddmmBackward0]
	1639163345744 -> 1639163345600
	1638868214864 [label="bert.encoder.layer.0.attention.self.query.bias
 (768)" fillcolor=lightblue]
	1638868214864 -> 1639163345744
	1639163345744 [label=AccumulateGrad]
	1639163345696 -> 1639163345600
	1639163345696 [label=ViewBackward0]
	1639163342864 -> 1639163345696
	1639163342864 [label=NativeLayerNormBackward0]
	1639163346176 -> 1639163342864
	1639163346176 [label=AddBackward0]
	1639163346368 -> 1639163346176
	1639163346368 [label=AddBackward0]
	1639163346512 -> 1639163346368
	1639163346512 [label=EmbeddingBackward0]
	1639163346656 -> 1639163346512
	1638863137456 [label="bert.embeddings.word_embeddings.weight
 (30000, 768)" fillcolor=lightblue]
	1638863137456 -> 1639163346656
	1639163346656 [label=AccumulateGrad]
	1639163346464 -> 1639163346368
	1639163346464 [label=EmbeddingBackward0]
	1639163346800 -> 1639163346464
	1638868214192 [label="bert.embeddings.token_type_embeddings.weight
 (2, 768)" fillcolor=lightblue]
	1638868214192 -> 1639163346800
	1639163346800 [label=AccumulateGrad]
	1639163346320 -> 1639163346176
	1639163346320 [label=EmbeddingBackward0]
	1639163346896 -> 1639163346320
	1638868214096 [label="bert.embeddings.position_embeddings.weight
 (512, 768)" fillcolor=lightblue]
	1638868214096 -> 1639163346896
	1639163346896 [label=AccumulateGrad]
	1639163346128 -> 1639163342864
	1638868214288 [label="bert.embeddings.LayerNorm.weight
 (768)" fillcolor=lightblue]
	1638868214288 -> 1639163346128
	1639163346128 [label=AccumulateGrad]
	1639163346080 -> 1639163342864
	1638868214384 [label="bert.embeddings.LayerNorm.bias
 (768)" fillcolor=lightblue]
	1638868214384 -> 1639163346080
	1639163346080 [label=AccumulateGrad]
	1639163345840 -> 1639163345600
	1639163345840 [label=TBackward0]
	1639163346272 -> 1639163345840
	1638868214768 [label="bert.encoder.layer.0.attention.self.query.weight
 (768, 768)" fillcolor=lightblue]
	1638868214768 -> 1639163346272
	1639163346272 [label=AccumulateGrad]
	1639163344640 -> 1639163344832
	1639163344640 [label=ReshapeAliasBackward0]
	1639163345264 -> 1639163344640
	1639163345264 [label=ExpandBackward0]
	1639163345552 -> 1639163345264
	1639163345552 [label=TransposeBackward0]
	1639163346224 -> 1639163345552
	1639163346224 [label=PermuteBackward0]
	1639163346848 -> 1639163346224
	1639163346848 [label=ViewBackward0]
	1639163346560 -> 1639163346848
	1639163346560 [label=ViewBackward0]
	1639163346416 -> 1639163346560
	1639163346416 [label=AddmmBackward0]
	1639163379872 -> 1639163346416
	1638868215056 [label="bert.encoder.layer.0.attention.self.key.bias
 (768)" fillcolor=lightblue]
	1638868215056 -> 1639163379872
	1639163379872 [label=AccumulateGrad]
	1639163379824 -> 1639163346416
	1639163379824 [label=ViewBackward0]
	1639163342864 -> 1639163379824
	1639163379776 -> 1639163346416
	1639163379776 [label=TBackward0]
	1639163380064 -> 1639163379776
	1638868214960 [label="bert.encoder.layer.0.attention.self.key.weight
 (768, 768)" fillcolor=lightblue]
	1638868214960 -> 1639163380064
	1639163380064 [label=AccumulateGrad]
	1639163343920 -> 1639163343824
	1639163343920 [label=ReshapeAliasBackward0]
	1639163344352 -> 1639163343920
	1639163344352 [label=ExpandBackward0]
	1639163344688 -> 1639163344352
	1639163344688 [label=PermuteBackward0]
	1639163344976 -> 1639163344688
	1639163344976 [label=ViewBackward0]
	1639163345408 -> 1639163344976
	1639163345408 [label=ViewBackward0]
	1639163346608 -> 1639163345408
	1639163346608 [label=AddmmBackward0]
	1639163345072 -> 1639163346608
	1638868215248 [label="bert.encoder.layer.0.attention.self.value.bias
 (768)" fillcolor=lightblue]
	1638868215248 -> 1639163345072
	1639163345072 [label=AccumulateGrad]
	1639163345936 -> 1639163346608
	1639163345936 [label=ViewBackward0]
	1639163342864 -> 1639163345936
	1639163344160 -> 1639163346608
	1639163344160 [label=TBackward0]
	1639163380112 -> 1639163344160
	1638868215152 [label="bert.encoder.layer.0.attention.self.value.weight
 (768, 768)" fillcolor=lightblue]
	1638868215152 -> 1639163380112
	1639163380112 [label=AccumulateGrad]
	1639163342960 -> 1639163343056
	1639163342960 [label=TBackward0]
	1639163343584 -> 1639163342960
	1638868215344 [label="bert.encoder.layer.0.attention.output.dense.weight
 (768, 768)" fillcolor=lightblue]
	1638868215344 -> 1639163343584
	1639163343584 [label=AccumulateGrad]
	1639163342864 -> 1639163342720
	1639163342672 -> 1639163341472
	1638868215536 [label="bert.encoder.layer.0.attention.output.LayerNorm.weight
 (768)" fillcolor=lightblue]
	1638868215536 -> 1639163342672
	1639163342672 [label=AccumulateGrad]
	1639163342624 -> 1639163341472
	1638868215632 [label="bert.encoder.layer.0.attention.output.LayerNorm.bias
 (768)" fillcolor=lightblue]
	1638868215632 -> 1639163342624
	1639163342624 [label=AccumulateGrad]
	1639163342384 -> 1639163342240
	1639163342384 [label=TBackward0]
	1639163342816 -> 1639163342384
	1638868215728 [label="bert.encoder.layer.0.intermediate.dense.weight
 (3072, 768)" fillcolor=lightblue]
	1638868215728 -> 1639163342816
	1639163342816 [label=AccumulateGrad]
	1639163341568 -> 1639163341664
	1639163341568 [label=TBackward0]
	1639163342192 -> 1639163341568
	1638868215920 [label="bert.encoder.layer.0.output.dense.weight
 (768, 3072)" fillcolor=lightblue]
	1638868215920 -> 1639163342192
	1639163342192 [label=AccumulateGrad]
	1639163341472 -> 1639163341328
	1639163341280 -> 1639163338016
	1638868216112 [label="bert.encoder.layer.0.output.LayerNorm.weight
 (768)" fillcolor=lightblue]
	1638868216112 -> 1639163341280
	1639163341280 [label=AccumulateGrad]
	1639163341232 -> 1639163338016
	1638868216208 [label="bert.encoder.layer.0.output.LayerNorm.bias
 (768)" fillcolor=lightblue]
	1638868216208 -> 1639163341232
	1639163341232 [label=AccumulateGrad]
	1639163340992 -> 1639163340752
	1639163340992 [label=TBackward0]
	1639163341424 -> 1639163340992
	1638868216304 [label="bert.encoder.layer.1.attention.self.query.weight
 (768, 768)" fillcolor=lightblue]
	1638868216304 -> 1639163341424
	1639163341424 [label=AccumulateGrad]
	1639163339792 -> 1639163339984
	1639163339792 [label=ReshapeAliasBackward0]
	1639163340416 -> 1639163339792
	1639163340416 [label=ExpandBackward0]
	1639163340704 -> 1639163340416
	1639163340704 [label=TransposeBackward0]
	1639163341376 -> 1639163340704
	1639163341376 [label=PermuteBackward0]
	1639163341616 -> 1639163341376
	1639163341616 [label=ViewBackward0]
	1639163342096 -> 1639163341616
	1639163342096 [label=ViewBackward0]
	1639163342432 -> 1639163342096
	1639163342432 [label=AddmmBackward0]
	1639163343200 -> 1639163342432
	1638868216592 [label="bert.encoder.layer.1.attention.self.key.bias
 (768)" fillcolor=lightblue]
	1638868216592 -> 1639163343200
	1639163343200 [label=AccumulateGrad]
	1639163342000 -> 1639163342432
	1639163342000 [label=ViewBackward0]
	1639163338016 -> 1639163342000
	1639163340224 -> 1639163342432
	1639163340224 [label=TBackward0]
	1639163343776 -> 1639163340224
	1638868216496 [label="bert.encoder.layer.1.attention.self.key.weight
 (768, 768)" fillcolor=lightblue]
	1638868216496 -> 1639163343776
	1639163343776 [label=AccumulateGrad]
	1639163339072 -> 1639163338976
	1639163339072 [label=ReshapeAliasBackward0]
	1639163339504 -> 1639163339072
	1639163339504 [label=ExpandBackward0]
	1639163339840 -> 1639163339504
	1639163339840 [label=PermuteBackward0]
	1639163340128 -> 1639163339840
	1639163340128 [label=ViewBackward0]
	1639163340560 -> 1639163340128
	1639163340560 [label=ViewBackward0]
	1639163341808 -> 1639163340560
	1639163341808 [label=AddmmBackward0]
	1639163342768 -> 1639163341808
	1638868216784 [label="bert.encoder.layer.1.attention.self.value.bias
 (768)" fillcolor=lightblue]
	1638868216784 -> 1639163342768
	1639163342768 [label=AccumulateGrad]
	1639163341088 -> 1639163341808
	1639163341088 [label=ViewBackward0]
	1639163338016 -> 1639163341088
	1639163339312 -> 1639163341808
	1639163339312 [label=TBackward0]
	1639163343440 -> 1639163339312
	1638868216688 [label="bert.encoder.layer.1.attention.self.value.weight
 (768, 768)" fillcolor=lightblue]
	1638868216688 -> 1639163343440
	1639163343440 [label=AccumulateGrad]
	1639163338112 -> 1639163338208
	1639163338112 [label=TBackward0]
	1639163338736 -> 1639163338112
	1638868216880 [label="bert.encoder.layer.1.attention.output.dense.weight
 (768, 768)" fillcolor=lightblue]
	1638868216880 -> 1639163338736
	1639163338736 [label=AccumulateGrad]
	1639163338016 -> 1639163337872
	1639163337824 -> 1639163336624
	1638868217072 [label="bert.encoder.layer.1.attention.output.LayerNorm.weight
 (768)" fillcolor=lightblue]
	1638868217072 -> 1639163337824
	1639163337824 [label=AccumulateGrad]
	1639163337776 -> 1639163336624
	1638868217168 [label="bert.encoder.layer.1.attention.output.LayerNorm.bias
 (768)" fillcolor=lightblue]
	1638868217168 -> 1639163337776
	1639163337776 [label=AccumulateGrad]
	1639163337536 -> 1639163337392
	1639163337536 [label=TBackward0]
	1639163337968 -> 1639163337536
	1638868217264 [label="bert.encoder.layer.1.intermediate.dense.weight
 (3072, 768)" fillcolor=lightblue]
	1638868217264 -> 1639163337968
	1639163337968 [label=AccumulateGrad]
	1639163336720 -> 1639163336816
	1639163336720 [label=TBackward0]
	1639163337344 -> 1639163336720
	1638868217456 [label="bert.encoder.layer.1.output.dense.weight
 (768, 3072)" fillcolor=lightblue]
	1638868217456 -> 1639163337344
	1639163337344 [label=AccumulateGrad]
	1639163336624 -> 1639163336480
	1639163336432 -> 1639163333168
	1638868217648 [label="bert.encoder.layer.1.output.LayerNorm.weight
 (768)" fillcolor=lightblue]
	1638868217648 -> 1639163336432
	1639163336432 [label=AccumulateGrad]
	1639163336384 -> 1639163333168
	1638868217744 [label="bert.encoder.layer.1.output.LayerNorm.bias
 (768)" fillcolor=lightblue]
	1638868217744 -> 1639163336384
	1639163336384 [label=AccumulateGrad]
	1639163336144 -> 1639163335904
	1639163336144 [label=TBackward0]
	1639163336576 -> 1639163336144
	1638868217840 [label="bert.encoder.layer.2.attention.self.query.weight
 (768, 768)" fillcolor=lightblue]
	1638868217840 -> 1639163336576
	1639163336576 [label=AccumulateGrad]
	1639163334944 -> 1639163335136
	1639163334944 [label=ReshapeAliasBackward0]
	1639163335568 -> 1639163334944
	1639163335568 [label=ExpandBackward0]
	1639163335856 -> 1639163335568
	1639163335856 [label=TransposeBackward0]
	1639163336528 -> 1639163335856
	1639163336528 [label=PermuteBackward0]
	1639163336768 -> 1639163336528
	1639163336768 [label=ViewBackward0]
	1639163337248 -> 1639163336768
	1639163337248 [label=ViewBackward0]
	1639163337584 -> 1639163337248
	1639163337584 [label=AddmmBackward0]
	1639163338352 -> 1639163337584
	1638868218128 [label="bert.encoder.layer.2.attention.self.key.bias
 (768)" fillcolor=lightblue]
	1638868218128 -> 1639163338352
	1639163338352 [label=AccumulateGrad]
	1639163337152 -> 1639163337584
	1639163337152 [label=ViewBackward0]
	1639163333168 -> 1639163337152
	1639163335376 -> 1639163337584
	1639163335376 [label=TBackward0]
	1639163338928 -> 1639163335376
	1638868218032 [label="bert.encoder.layer.2.attention.self.key.weight
 (768, 768)" fillcolor=lightblue]
	1638868218032 -> 1639163338928
	1639163338928 [label=AccumulateGrad]
	1639163334224 -> 1639163334128
	1639163334224 [label=ReshapeAliasBackward0]
	1639163334656 -> 1639163334224
	1639163334656 [label=ExpandBackward0]
	1639163334992 -> 1639163334656
	1639163334992 [label=PermuteBackward0]
	1639163335280 -> 1639163334992
	1639163335280 [label=ViewBackward0]
	1639163335712 -> 1639163335280
	1639163335712 [label=ViewBackward0]
	1639163336960 -> 1639163335712
	1639163336960 [label=AddmmBackward0]
	1639163337920 -> 1639163336960
	1638868218320 [label="bert.encoder.layer.2.attention.self.value.bias
 (768)" fillcolor=lightblue]
	1638868218320 -> 1639163337920
	1639163337920 [label=AccumulateGrad]
	1639163336240 -> 1639163336960
	1639163336240 [label=ViewBackward0]
	1639163333168 -> 1639163336240
	1639163334464 -> 1639163336960
	1639163334464 [label=TBackward0]
	1639163338592 -> 1639163334464
	1638868218224 [label="bert.encoder.layer.2.attention.self.value.weight
 (768, 768)" fillcolor=lightblue]
	1638868218224 -> 1639163338592
	1639163338592 [label=AccumulateGrad]
	1639163333264 -> 1639163333360
	1639163333264 [label=TBackward0]
	1639163333888 -> 1639163333264
	1638868218416 [label="bert.encoder.layer.2.attention.output.dense.weight
 (768, 768)" fillcolor=lightblue]
	1638868218416 -> 1639163333888
	1639163333888 [label=AccumulateGrad]
	1639163333168 -> 1639163333024
	1639163332976 -> 1639163331776
	1638868218608 [label="bert.encoder.layer.2.attention.output.LayerNorm.weight
 (768)" fillcolor=lightblue]
	1638868218608 -> 1639163332976
	1639163332976 [label=AccumulateGrad]
	1639163332928 -> 1639163331776
	1638868218704 [label="bert.encoder.layer.2.attention.output.LayerNorm.bias
 (768)" fillcolor=lightblue]
	1638868218704 -> 1639163332928
	1639163332928 [label=AccumulateGrad]
	1639163332688 -> 1639163332544
	1639163332688 [label=TBackward0]
	1639163333120 -> 1639163332688
	1638868218800 [label="bert.encoder.layer.2.intermediate.dense.weight
 (3072, 768)" fillcolor=lightblue]
	1638868218800 -> 1639163333120
	1639163333120 [label=AccumulateGrad]
	1639163331872 -> 1639163331968
	1639163331872 [label=TBackward0]
	1639163332496 -> 1639163331872
	1638868218992 [label="bert.encoder.layer.2.output.dense.weight
 (768, 3072)" fillcolor=lightblue]
	1638868218992 -> 1639163332496
	1639163332496 [label=AccumulateGrad]
	1639163331776 -> 1639163331632
	1639163331584 -> 1639163311872
	1638868219184 [label="bert.encoder.layer.2.output.LayerNorm.weight
 (768)" fillcolor=lightblue]
	1638868219184 -> 1639163331584
	1639163331584 [label=AccumulateGrad]
	1639163331536 -> 1639163311872
	1638868219280 [label="bert.encoder.layer.2.output.LayerNorm.bias
 (768)" fillcolor=lightblue]
	1638868219280 -> 1639163331536
	1639163331536 [label=AccumulateGrad]
	1639163331296 -> 1639163331056
	1639163331296 [label=TBackward0]
	1639163331728 -> 1639163331296
	1638868219376 [label="bert.encoder.layer.3.attention.self.query.weight
 (768, 768)" fillcolor=lightblue]
	1638868219376 -> 1639163331728
	1639163331728 [label=AccumulateGrad]
	1639163313648 -> 1639163313840
	1639163313648 [label=ReshapeAliasBackward0]
	1639163314080 -> 1639163313648
	1639163314080 [label=ExpandBackward0]
	1639163331008 -> 1639163314080
	1639163331008 [label=TransposeBackward0]
	1639163331680 -> 1639163331008
	1639163331680 [label=PermuteBackward0]
	1639163331920 -> 1639163331680
	1639163331920 [label=ViewBackward0]
	1639163332400 -> 1639163331920
	1639163332400 [label=ViewBackward0]
	1639163332736 -> 1639163332400
	1639163332736 [label=AddmmBackward0]
	1639163333504 -> 1639163332736
	1638868219664 [label="bert.encoder.layer.3.attention.self.key.bias
 (768)" fillcolor=lightblue]
	1638868219664 -> 1639163333504
	1639163333504 [label=AccumulateGrad]
	1639163332304 -> 1639163332736
	1639163332304 [label=ViewBackward0]
	1639163311872 -> 1639163332304
	1639163330624 -> 1639163332736
	1639163330624 [label=TBackward0]
	1639163334080 -> 1639163330624
	1638868219568 [label="bert.encoder.layer.3.attention.self.key.weight
 (768, 768)" fillcolor=lightblue]
	1638868219568 -> 1639163334080
	1639163334080 [label=AccumulateGrad]
	1639163312928 -> 1639163312832
	1639163312928 [label=ReshapeAliasBackward0]
	1639163313360 -> 1639163312928
	1639163313360 [label=ExpandBackward0]
	1639163313696 -> 1639163313360
	1639163313696 [label=PermuteBackward0]
	1639163313984 -> 1639163313696
	1639163313984 [label=ViewBackward0]
	1639163313168 -> 1639163313984
	1639163313168 [label=ViewBackward0]
	1639163332112 -> 1639163313168
	1639163332112 [label=AddmmBackward0]
	1639163333072 -> 1639163332112
	1638868219856 [label="bert.encoder.layer.3.attention.self.value.bias
 (768)" fillcolor=lightblue]
	1638868219856 -> 1639163333072
	1639163333072 [label=AccumulateGrad]
	1639163331392 -> 1639163332112
	1639163331392 [label=ViewBackward0]
	1639163311872 -> 1639163331392
	1639163330720 -> 1639163332112
	1639163330720 [label=TBackward0]
	1639163333744 -> 1639163330720
	1638868219760 [label="bert.encoder.layer.3.attention.self.value.weight
 (768, 768)" fillcolor=lightblue]
	1638868219760 -> 1639163333744
	1639163333744 [label=AccumulateGrad]
	1639163311968 -> 1639163312064
	1639163311968 [label=TBackward0]
	1639163312592 -> 1639163311968
	1638868219952 [label="bert.encoder.layer.3.attention.output.dense.weight
 (768, 768)" fillcolor=lightblue]
	1638868219952 -> 1639163312592
	1639163312592 [label=AccumulateGrad]
	1639163311872 -> 1639163311728
	1639163311680 -> 1639163310480
	1638868220144 [label="bert.encoder.layer.3.attention.output.LayerNorm.weight
 (768)" fillcolor=lightblue]
	1638868220144 -> 1639163311680
	1639163311680 [label=AccumulateGrad]
	1639163311632 -> 1639163310480
	1638868220240 [label="bert.encoder.layer.3.attention.output.LayerNorm.bias
 (768)" fillcolor=lightblue]
	1638868220240 -> 1639163311632
	1639163311632 [label=AccumulateGrad]
	1639163311392 -> 1639163311248
	1639163311392 [label=TBackward0]
	1639163311824 -> 1639163311392
	1638868220336 [label="bert.encoder.layer.3.intermediate.dense.weight
 (3072, 768)" fillcolor=lightblue]
	1638868220336 -> 1639163311824
	1639163311824 [label=AccumulateGrad]
	1639163310576 -> 1639163310672
	1639163310576 [label=TBackward0]
	1639163311200 -> 1639163310576
	1638868220528 [label="bert.encoder.layer.3.output.dense.weight
 (768, 3072)" fillcolor=lightblue]
	1638868220528 -> 1639163311200
	1639163311200 [label=AccumulateGrad]
	1639163310480 -> 1639163310336
	1639163310288 -> 1639163307024
	1638868220720 [label="bert.encoder.layer.3.output.LayerNorm.weight
 (768)" fillcolor=lightblue]
	1638868220720 -> 1639163310288
	1639163310288 [label=AccumulateGrad]
	1639163310240 -> 1639163307024
	1638868220816 [label="bert.encoder.layer.3.output.LayerNorm.bias
 (768)" fillcolor=lightblue]
	1638868220816 -> 1639163310240
	1639163310240 [label=AccumulateGrad]
	1639163310000 -> 1639163309760
	1639163310000 [label=TBackward0]
	1639163310432 -> 1639163310000
	1638868220912 [label="bert.encoder.layer.4.attention.self.query.weight
 (768, 768)" fillcolor=lightblue]
	1638868220912 -> 1639163310432
	1639163310432 [label=AccumulateGrad]
	1639163308800 -> 1639163308992
	1639163308800 [label=ReshapeAliasBackward0]
	1639163309424 -> 1639163308800
	1639163309424 [label=ExpandBackward0]
	1639163309712 -> 1639163309424
	1639163309712 [label=TransposeBackward0]
	1639163310384 -> 1639163309712
	1639163310384 [label=PermuteBackward0]
	1639163310624 -> 1639163310384
	1639163310624 [label=ViewBackward0]
	1639163311104 -> 1639163310624
	1639163311104 [label=ViewBackward0]
	1639163311440 -> 1639163311104
	1639163311440 [label=AddmmBackward0]
	1639163312208 -> 1639163311440
	1638868221200 [label="bert.encoder.layer.4.attention.self.key.bias
 (768)" fillcolor=lightblue]
	1638868221200 -> 1639163312208
	1639163312208 [label=AccumulateGrad]
	1639163311008 -> 1639163311440
	1639163311008 [label=ViewBackward0]
	1639163307024 -> 1639163311008
	1639163309232 -> 1639163311440
	1639163309232 [label=TBackward0]
	1639163312784 -> 1639163309232
	1638868221104 [label="bert.encoder.layer.4.attention.self.key.weight
 (768, 768)" fillcolor=lightblue]
	1638868221104 -> 1639163312784
	1639163312784 [label=AccumulateGrad]
	1639163308080 -> 1639163307984
	1639163308080 [label=ReshapeAliasBackward0]
	1639163308512 -> 1639163308080
	1639163308512 [label=ExpandBackward0]
	1639163308848 -> 1639163308512
	1639163308848 [label=PermuteBackward0]
	1639163309136 -> 1639163308848
	1639163309136 [label=ViewBackward0]
	1639163309568 -> 1639163309136
	1639163309568 [label=ViewBackward0]
	1639163310816 -> 1639163309568
	1639163310816 [label=AddmmBackward0]
	1639163311776 -> 1639163310816
	1638868221392 [label="bert.encoder.layer.4.attention.self.value.bias
 (768)" fillcolor=lightblue]
	1638868221392 -> 1639163311776
	1639163311776 [label=AccumulateGrad]
	1639163310096 -> 1639163310816
	1639163310096 [label=ViewBackward0]
	1639163307024 -> 1639163310096
	1639163308320 -> 1639163310816
	1639163308320 [label=TBackward0]
	1639163312448 -> 1639163308320
	1638868221296 [label="bert.encoder.layer.4.attention.self.value.weight
 (768, 768)" fillcolor=lightblue]
	1638868221296 -> 1639163312448
	1639163312448 [label=AccumulateGrad]
	1639163307120 -> 1639163307216
	1639163307120 [label=TBackward0]
	1639163307744 -> 1639163307120
	1638868221488 [label="bert.encoder.layer.4.attention.output.dense.weight
 (768, 768)" fillcolor=lightblue]
	1638868221488 -> 1639163307744
	1639163307744 [label=AccumulateGrad]
	1639163307024 -> 1639163306880
	1639163306832 -> 1639163305632
	1638868221680 [label="bert.encoder.layer.4.attention.output.LayerNorm.weight
 (768)" fillcolor=lightblue]
	1638868221680 -> 1639163306832
	1639163306832 [label=AccumulateGrad]
	1639163306784 -> 1639163305632
	1638868221776 [label="bert.encoder.layer.4.attention.output.LayerNorm.bias
 (768)" fillcolor=lightblue]
	1638868221776 -> 1639163306784
	1639163306784 [label=AccumulateGrad]
	1639163306544 -> 1639163306400
	1639163306544 [label=TBackward0]
	1639163306976 -> 1639163306544
	1638868221872 [label="bert.encoder.layer.4.intermediate.dense.weight
 (3072, 768)" fillcolor=lightblue]
	1638868221872 -> 1639163306976
	1639163306976 [label=AccumulateGrad]
	1639163305728 -> 1639163305824
	1639163305728 [label=TBackward0]
	1639163306352 -> 1639163305728
	1638868467888 [label="bert.encoder.layer.4.output.dense.weight
 (768, 3072)" fillcolor=lightblue]
	1638868467888 -> 1639163306352
	1639163306352 [label=AccumulateGrad]
	1639163305632 -> 1639163305488
	1639163305440 -> 1639163302176
	1638868468080 [label="bert.encoder.layer.4.output.LayerNorm.weight
 (768)" fillcolor=lightblue]
	1638868468080 -> 1639163305440
	1639163305440 [label=AccumulateGrad]
	1639163305392 -> 1639163302176
	1638868468176 [label="bert.encoder.layer.4.output.LayerNorm.bias
 (768)" fillcolor=lightblue]
	1638868468176 -> 1639163305392
	1639163305392 [label=AccumulateGrad]
	1639163305152 -> 1639163304912
	1639163305152 [label=TBackward0]
	1639163305584 -> 1639163305152
	1638868468272 [label="bert.encoder.layer.5.attention.self.query.weight
 (768, 768)" fillcolor=lightblue]
	1638868468272 -> 1639163305584
	1639163305584 [label=AccumulateGrad]
	1639163303952 -> 1639163304144
	1639163303952 [label=ReshapeAliasBackward0]
	1639163304576 -> 1639163303952
	1639163304576 [label=ExpandBackward0]
	1639163304864 -> 1639163304576
	1639163304864 [label=TransposeBackward0]
	1639163305536 -> 1639163304864
	1639163305536 [label=PermuteBackward0]
	1639163305776 -> 1639163305536
	1639163305776 [label=ViewBackward0]
	1639163306256 -> 1639163305776
	1639163306256 [label=ViewBackward0]
	1639163306592 -> 1639163306256
	1639163306592 [label=AddmmBackward0]
	1639163307360 -> 1639163306592
	1638868468560 [label="bert.encoder.layer.5.attention.self.key.bias
 (768)" fillcolor=lightblue]
	1638868468560 -> 1639163307360
	1639163307360 [label=AccumulateGrad]
	1639163306160 -> 1639163306592
	1639163306160 [label=ViewBackward0]
	1639163302176 -> 1639163306160
	1639163304384 -> 1639163306592
	1639163304384 [label=TBackward0]
	1639163307936 -> 1639163304384
	1638868468464 [label="bert.encoder.layer.5.attention.self.key.weight
 (768, 768)" fillcolor=lightblue]
	1638868468464 -> 1639163307936
	1639163307936 [label=AccumulateGrad]
	1639163303232 -> 1639163303136
	1639163303232 [label=ReshapeAliasBackward0]
	1639163303664 -> 1639163303232
	1639163303664 [label=ExpandBackward0]
	1639163304000 -> 1639163303664
	1639163304000 [label=PermuteBackward0]
	1639163304288 -> 1639163304000
	1639163304288 [label=ViewBackward0]
	1639163304720 -> 1639163304288
	1639163304720 [label=ViewBackward0]
	1639163305968 -> 1639163304720
	1639163305968 [label=AddmmBackward0]
	1639163306928 -> 1639163305968
	1638868468752 [label="bert.encoder.layer.5.attention.self.value.bias
 (768)" fillcolor=lightblue]
	1638868468752 -> 1639163306928
	1639163306928 [label=AccumulateGrad]
	1639163305248 -> 1639163305968
	1639163305248 [label=ViewBackward0]
	1639163302176 -> 1639163305248
	1639163303472 -> 1639163305968
	1639163303472 [label=TBackward0]
	1639163307600 -> 1639163303472
	1638868468656 [label="bert.encoder.layer.5.attention.self.value.weight
 (768, 768)" fillcolor=lightblue]
	1638868468656 -> 1639163307600
	1639163307600 [label=AccumulateGrad]
	1639163302272 -> 1639163302368
	1639163302272 [label=TBackward0]
	1639163302896 -> 1639163302272
	1638868468848 [label="bert.encoder.layer.5.attention.output.dense.weight
 (768, 768)" fillcolor=lightblue]
	1638868468848 -> 1639163302896
	1639163302896 [label=AccumulateGrad]
	1639163302176 -> 1639163302032
	1639163301984 -> 1639163300784
	1638868469040 [label="bert.encoder.layer.5.attention.output.LayerNorm.weight
 (768)" fillcolor=lightblue]
	1638868469040 -> 1639163301984
	1639163301984 [label=AccumulateGrad]
	1639163301936 -> 1639163300784
	1638868469136 [label="bert.encoder.layer.5.attention.output.LayerNorm.bias
 (768)" fillcolor=lightblue]
	1638868469136 -> 1639163301936
	1639163301936 [label=AccumulateGrad]
	1639163301696 -> 1639163301552
	1639163301696 [label=TBackward0]
	1639163302128 -> 1639163301696
	1638868469232 [label="bert.encoder.layer.5.intermediate.dense.weight
 (3072, 768)" fillcolor=lightblue]
	1638868469232 -> 1639163302128
	1639163302128 [label=AccumulateGrad]
	1639163300880 -> 1639163300976
	1639163300880 [label=TBackward0]
	1639163301504 -> 1639163300880
	1638868469424 [label="bert.encoder.layer.5.output.dense.weight
 (768, 3072)" fillcolor=lightblue]
	1638868469424 -> 1639163301504
	1639163301504 [label=AccumulateGrad]
	1639163300784 -> 1639163300640
	1639163300592 -> 1638912654832
	1638868469616 [label="bert.encoder.layer.5.output.LayerNorm.weight
 (768)" fillcolor=lightblue]
	1638868469616 -> 1639163300592
	1639163300592 [label=AccumulateGrad]
	1639163300544 -> 1638912654832
	1638868469712 [label="bert.encoder.layer.5.output.LayerNorm.bias
 (768)" fillcolor=lightblue]
	1638868469712 -> 1639163300544
	1639163300544 [label=AccumulateGrad]
	1639163300304 -> 1639163300064
	1639163300304 [label=TBackward0]
	1639163300736 -> 1639163300304
	1638868469808 [label="bert.encoder.layer.6.attention.self.query.weight
 (768, 768)" fillcolor=lightblue]
	1638868469808 -> 1639163300736
	1639163300736 [label=AccumulateGrad]
	1639163299104 -> 1639163299296
	1639163299104 [label=ReshapeAliasBackward0]
	1639163299728 -> 1639163299104
	1639163299728 [label=ExpandBackward0]
	1639163300016 -> 1639163299728
	1639163300016 [label=TransposeBackward0]
	1639163300688 -> 1639163300016
	1639163300688 [label=PermuteBackward0]
	1639163300928 -> 1639163300688
	1639163300928 [label=ViewBackward0]
	1639163301408 -> 1639163300928
	1639163301408 [label=ViewBackward0]
	1639163301744 -> 1639163301408
	1639163301744 [label=AddmmBackward0]
	1639163302512 -> 1639163301744
	1638868470096 [label="bert.encoder.layer.6.attention.self.key.bias
 (768)" fillcolor=lightblue]
	1638868470096 -> 1639163302512
	1639163302512 [label=AccumulateGrad]
	1639163301312 -> 1639163301744
	1639163301312 [label=ViewBackward0]
	1638912654832 -> 1639163301312
	1639163299536 -> 1639163301744
	1639163299536 [label=TBackward0]
	1639163303088 -> 1639163299536
	1638868470000 [label="bert.encoder.layer.6.attention.self.key.weight
 (768, 768)" fillcolor=lightblue]
	1638868470000 -> 1639163303088
	1639163303088 [label=AccumulateGrad]
	1639163298384 -> 1639163298288
	1639163298384 [label=ReshapeAliasBackward0]
	1639163298816 -> 1639163298384
	1639163298816 [label=ExpandBackward0]
	1639163299152 -> 1639163298816
	1639163299152 [label=PermuteBackward0]
	1639163299440 -> 1639163299152
	1639163299440 [label=ViewBackward0]
	1639163299872 -> 1639163299440
	1639163299872 [label=ViewBackward0]
	1639163301120 -> 1639163299872
	1639163301120 [label=AddmmBackward0]
	1639163302080 -> 1639163301120
	1638868470288 [label="bert.encoder.layer.6.attention.self.value.bias
 (768)" fillcolor=lightblue]
	1638868470288 -> 1639163302080
	1639163302080 [label=AccumulateGrad]
	1639163300400 -> 1639163301120
	1639163300400 [label=ViewBackward0]
	1638912654832 -> 1639163300400
	1639163298624 -> 1639163301120
	1639163298624 [label=TBackward0]
	1639163302752 -> 1639163298624
	1638868470192 [label="bert.encoder.layer.6.attention.self.value.weight
 (768, 768)" fillcolor=lightblue]
	1638868470192 -> 1639163302752
	1639163302752 [label=AccumulateGrad]
	1638912654928 -> 1638912655024
	1638912654928 [label=TBackward0]
	1639163298048 -> 1638912654928
	1638868470384 [label="bert.encoder.layer.6.attention.output.dense.weight
 (768, 768)" fillcolor=lightblue]
	1638868470384 -> 1639163298048
	1639163298048 [label=AccumulateGrad]
	1638912654832 -> 1638912654688
	1638912654640 -> 1638912653440
	1638868470576 [label="bert.encoder.layer.6.attention.output.LayerNorm.weight
 (768)" fillcolor=lightblue]
	1638868470576 -> 1638912654640
	1638912654640 [label=AccumulateGrad]
	1638912654592 -> 1638912653440
	1638868470672 [label="bert.encoder.layer.6.attention.output.LayerNorm.bias
 (768)" fillcolor=lightblue]
	1638868470672 -> 1638912654592
	1638912654592 [label=AccumulateGrad]
	1638912654352 -> 1638912654208
	1638912654352 [label=TBackward0]
	1638912654784 -> 1638912654352
	1638868470768 [label="bert.encoder.layer.6.intermediate.dense.weight
 (3072, 768)" fillcolor=lightblue]
	1638868470768 -> 1638912654784
	1638912654784 [label=AccumulateGrad]
	1638912653536 -> 1638912653632
	1638912653536 [label=TBackward0]
	1638912654160 -> 1638912653536
	1638868470960 [label="bert.encoder.layer.6.output.dense.weight
 (768, 3072)" fillcolor=lightblue]
	1638868470960 -> 1638912654160
	1638912654160 [label=AccumulateGrad]
	1638912653440 -> 1638912653296
	1638912653248 -> 1638912649984
	1638868471152 [label="bert.encoder.layer.6.output.LayerNorm.weight
 (768)" fillcolor=lightblue]
	1638868471152 -> 1638912653248
	1638912653248 [label=AccumulateGrad]
	1638912653200 -> 1638912649984
	1638868471248 [label="bert.encoder.layer.6.output.LayerNorm.bias
 (768)" fillcolor=lightblue]
	1638868471248 -> 1638912653200
	1638912653200 [label=AccumulateGrad]
	1638912652960 -> 1638912652720
	1638912652960 [label=TBackward0]
	1638912653392 -> 1638912652960
	1638868471344 [label="bert.encoder.layer.7.attention.self.query.weight
 (768, 768)" fillcolor=lightblue]
	1638868471344 -> 1638912653392
	1638912653392 [label=AccumulateGrad]
	1638912651760 -> 1638912651952
	1638912651760 [label=ReshapeAliasBackward0]
	1638912652384 -> 1638912651760
	1638912652384 [label=ExpandBackward0]
	1638912652672 -> 1638912652384
	1638912652672 [label=TransposeBackward0]
	1638912653344 -> 1638912652672
	1638912653344 [label=PermuteBackward0]
	1638912653584 -> 1638912653344
	1638912653584 [label=ViewBackward0]
	1638912654064 -> 1638912653584
	1638912654064 [label=ViewBackward0]
	1638912654400 -> 1638912654064
	1638912654400 [label=AddmmBackward0]
	1638912655168 -> 1638912654400
	1638868471632 [label="bert.encoder.layer.7.attention.self.key.bias
 (768)" fillcolor=lightblue]
	1638868471632 -> 1638912655168
	1638912655168 [label=AccumulateGrad]
	1638912653968 -> 1638912654400
	1638912653968 [label=ViewBackward0]
	1638912649984 -> 1638912653968
	1638912652192 -> 1638912654400
	1638912652192 [label=TBackward0]
	1638912654448 -> 1638912652192
	1638868471536 [label="bert.encoder.layer.7.attention.self.key.weight
 (768, 768)" fillcolor=lightblue]
	1638868471536 -> 1638912654448
	1638912654448 [label=AccumulateGrad]
	1638912651040 -> 1638912650944
	1638912651040 [label=ReshapeAliasBackward0]
	1638912651472 -> 1638912651040
	1638912651472 [label=ExpandBackward0]
	1638912651808 -> 1638912651472
	1638912651808 [label=PermuteBackward0]
	1638912652096 -> 1638912651808
	1638912652096 [label=ViewBackward0]
	1638912652528 -> 1638912652096
	1638912652528 [label=ViewBackward0]
	1638912653776 -> 1638912652528
	1638912653776 [label=AddmmBackward0]
	1638912654736 -> 1638912653776
	1638868471824 [label="bert.encoder.layer.7.attention.self.value.bias
 (768)" fillcolor=lightblue]
	1638868471824 -> 1638912654736
	1638912654736 [label=AccumulateGrad]
	1638912653056 -> 1638912653776
	1638912653056 [label=ViewBackward0]
	1638912649984 -> 1638912653056
	1638912651280 -> 1638912653776
	1638912651280 [label=TBackward0]
	1639163297904 -> 1638912651280
	1638868471728 [label="bert.encoder.layer.7.attention.self.value.weight
 (768, 768)" fillcolor=lightblue]
	1638868471728 -> 1639163297904
	1639163297904 [label=AccumulateGrad]
	1638912650080 -> 1638912650176
	1638912650080 [label=TBackward0]
	1638912650704 -> 1638912650080
	1638868471920 [label="bert.encoder.layer.7.attention.output.dense.weight
 (768, 768)" fillcolor=lightblue]
	1638868471920 -> 1638912650704
	1638912650704 [label=AccumulateGrad]
	1638912649984 -> 1638912649840
	1638912649792 -> 1638912648592
	1638868472112 [label="bert.encoder.layer.7.attention.output.LayerNorm.weight
 (768)" fillcolor=lightblue]
	1638868472112 -> 1638912649792
	1638912649792 [label=AccumulateGrad]
	1638912649744 -> 1638912648592
	1638868472208 [label="bert.encoder.layer.7.attention.output.LayerNorm.bias
 (768)" fillcolor=lightblue]
	1638868472208 -> 1638912649744
	1638912649744 [label=AccumulateGrad]
	1638912649504 -> 1638912649360
	1638912649504 [label=TBackward0]
	1638912649936 -> 1638912649504
	1638868472304 [label="bert.encoder.layer.7.intermediate.dense.weight
 (3072, 768)" fillcolor=lightblue]
	1638868472304 -> 1638912649936
	1638912649936 [label=AccumulateGrad]
	1638912648688 -> 1638912648784
	1638912648688 [label=TBackward0]
	1638912649312 -> 1638912648688
	1638868472496 [label="bert.encoder.layer.7.output.dense.weight
 (768, 3072)" fillcolor=lightblue]
	1638868472496 -> 1638912649312
	1638912649312 [label=AccumulateGrad]
	1638912648592 -> 1638912648448
	1638912648400 -> 1638912645136
	1638868472688 [label="bert.encoder.layer.7.output.LayerNorm.weight
 (768)" fillcolor=lightblue]
	1638868472688 -> 1638912648400
	1638912648400 [label=AccumulateGrad]
	1638912648352 -> 1638912645136
	1638868472784 [label="bert.encoder.layer.7.output.LayerNorm.bias
 (768)" fillcolor=lightblue]
	1638868472784 -> 1638912648352
	1638912648352 [label=AccumulateGrad]
	1638912648112 -> 1638912647872
	1638912648112 [label=TBackward0]
	1638912648544 -> 1638912648112
	1638868472880 [label="bert.encoder.layer.8.attention.self.query.weight
 (768, 768)" fillcolor=lightblue]
	1638868472880 -> 1638912648544
	1638912648544 [label=AccumulateGrad]
	1638912646912 -> 1638912647104
	1638912646912 [label=ReshapeAliasBackward0]
	1638912647536 -> 1638912646912
	1638912647536 [label=ExpandBackward0]
	1638912647824 -> 1638912647536
	1638912647824 [label=TransposeBackward0]
	1638912648496 -> 1638912647824
	1638912648496 [label=PermuteBackward0]
	1638912648736 -> 1638912648496
	1638912648736 [label=ViewBackward0]
	1638912649216 -> 1638912648736
	1638912649216 [label=ViewBackward0]
	1638912649552 -> 1638912649216
	1638912649552 [label=AddmmBackward0]
	1638912650320 -> 1638912649552
	1638868473168 [label="bert.encoder.layer.8.attention.self.key.bias
 (768)" fillcolor=lightblue]
	1638868473168 -> 1638912650320
	1638912650320 [label=AccumulateGrad]
	1638912649120 -> 1638912649552
	1638912649120 [label=ViewBackward0]
	1638912645136 -> 1638912649120
	1638912647344 -> 1638912649552
	1638912647344 [label=TBackward0]
	1638912650896 -> 1638912647344
	1638868473072 [label="bert.encoder.layer.8.attention.self.key.weight
 (768, 768)" fillcolor=lightblue]
	1638868473072 -> 1638912650896
	1638912650896 [label=AccumulateGrad]
	1638912646192 -> 1638912646096
	1638912646192 [label=ReshapeAliasBackward0]
	1638912646624 -> 1638912646192
	1638912646624 [label=ExpandBackward0]
	1638912646960 -> 1638912646624
	1638912646960 [label=PermuteBackward0]
	1638912647248 -> 1638912646960
	1638912647248 [label=ViewBackward0]
	1638912647680 -> 1638912647248
	1638912647680 [label=ViewBackward0]
	1638912648928 -> 1638912647680
	1638912648928 [label=AddmmBackward0]
	1638912649888 -> 1638912648928
	1638868473360 [label="bert.encoder.layer.8.attention.self.value.bias
 (768)" fillcolor=lightblue]
	1638868473360 -> 1638912649888
	1638912649888 [label=AccumulateGrad]
	1638912648208 -> 1638912648928
	1638912648208 [label=ViewBackward0]
	1638912645136 -> 1638912648208
	1638912646432 -> 1638912648928
	1638912646432 [label=TBackward0]
	1638912650560 -> 1638912646432
	1638868473264 [label="bert.encoder.layer.8.attention.self.value.weight
 (768, 768)" fillcolor=lightblue]
	1638868473264 -> 1638912650560
	1638912650560 [label=AccumulateGrad]
	1638912645232 -> 1638912645328
	1638912645232 [label=TBackward0]
	1638912645856 -> 1638912645232
	1638868473456 [label="bert.encoder.layer.8.attention.output.dense.weight
 (768, 768)" fillcolor=lightblue]
	1638868473456 -> 1638912645856
	1638912645856 [label=AccumulateGrad]
	1638912645136 -> 1638912644992
	1638912644944 -> 1638912643744
	1638868473648 [label="bert.encoder.layer.8.attention.output.LayerNorm.weight
 (768)" fillcolor=lightblue]
	1638868473648 -> 1638912644944
	1638912644944 [label=AccumulateGrad]
	1638912644896 -> 1638912643744
	1638868473744 [label="bert.encoder.layer.8.attention.output.LayerNorm.bias
 (768)" fillcolor=lightblue]
	1638868473744 -> 1638912644896
	1638912644896 [label=AccumulateGrad]
	1638912644656 -> 1638912644512
	1638912644656 [label=TBackward0]
	1638912645088 -> 1638912644656
	1638868473840 [label="bert.encoder.layer.8.intermediate.dense.weight
 (3072, 768)" fillcolor=lightblue]
	1638868473840 -> 1638912645088
	1638912645088 [label=AccumulateGrad]
	1638912643840 -> 1638912643936
	1638912643840 [label=TBackward0]
	1638912644464 -> 1638912643840
	1638868474032 [label="bert.encoder.layer.8.output.dense.weight
 (768, 3072)" fillcolor=lightblue]
	1638868474032 -> 1638912644464
	1638912644464 [label=AccumulateGrad]
	1638912643744 -> 1638912643600
	1638912643552 -> 1638912640288
	1638868474224 [label="bert.encoder.layer.8.output.LayerNorm.weight
 (768)" fillcolor=lightblue]
	1638868474224 -> 1638912643552
	1638912643552 [label=AccumulateGrad]
	1638912643504 -> 1638912640288
	1638868474320 [label="bert.encoder.layer.8.output.LayerNorm.bias
 (768)" fillcolor=lightblue]
	1638868474320 -> 1638912643504
	1638912643504 [label=AccumulateGrad]
	1638912643264 -> 1638912643024
	1638912643264 [label=TBackward0]
	1638912643696 -> 1638912643264
	1638868474416 [label="bert.encoder.layer.9.attention.self.query.weight
 (768, 768)" fillcolor=lightblue]
	1638868474416 -> 1638912643696
	1638912643696 [label=AccumulateGrad]
	1638912642064 -> 1638912642256
	1638912642064 [label=ReshapeAliasBackward0]
	1638912642688 -> 1638912642064
	1638912642688 [label=ExpandBackward0]
	1638912642976 -> 1638912642688
	1638912642976 [label=TransposeBackward0]
	1638912643648 -> 1638912642976
	1638912643648 [label=PermuteBackward0]
	1638912643888 -> 1638912643648
	1638912643888 [label=ViewBackward0]
	1638912644368 -> 1638912643888
	1638912644368 [label=ViewBackward0]
	1638912644704 -> 1638912644368
	1638912644704 [label=AddmmBackward0]
	1638912645472 -> 1638912644704
	1638868474704 [label="bert.encoder.layer.9.attention.self.key.bias
 (768)" fillcolor=lightblue]
	1638868474704 -> 1638912645472
	1638912645472 [label=AccumulateGrad]
	1638912644272 -> 1638912644704
	1638912644272 [label=ViewBackward0]
	1638912640288 -> 1638912644272
	1638912642496 -> 1638912644704
	1638912642496 [label=TBackward0]
	1638912646048 -> 1638912642496
	1638868474608 [label="bert.encoder.layer.9.attention.self.key.weight
 (768, 768)" fillcolor=lightblue]
	1638868474608 -> 1638912646048
	1638912646048 [label=AccumulateGrad]
	1638912641344 -> 1638912641248
	1638912641344 [label=ReshapeAliasBackward0]
	1638912641776 -> 1638912641344
	1638912641776 [label=ExpandBackward0]
	1638912642112 -> 1638912641776
	1638912642112 [label=PermuteBackward0]
	1638912642400 -> 1638912642112
	1638912642400 [label=ViewBackward0]
	1638912642832 -> 1638912642400
	1638912642832 [label=ViewBackward0]
	1638912644080 -> 1638912642832
	1638912644080 [label=AddmmBackward0]
	1638912645040 -> 1638912644080
	1638868474896 [label="bert.encoder.layer.9.attention.self.value.bias
 (768)" fillcolor=lightblue]
	1638868474896 -> 1638912645040
	1638912645040 [label=AccumulateGrad]
	1638912643360 -> 1638912644080
	1638912643360 [label=ViewBackward0]
	1638912640288 -> 1638912643360
	1638912641584 -> 1638912644080
	1638912641584 [label=TBackward0]
	1638912645712 -> 1638912641584
	1638868474800 [label="bert.encoder.layer.9.attention.self.value.weight
 (768, 768)" fillcolor=lightblue]
	1638868474800 -> 1638912645712
	1638912645712 [label=AccumulateGrad]
	1638912640384 -> 1638912640480
	1638912640384 [label=TBackward0]
	1638912641008 -> 1638912640384
	1638868474992 [label="bert.encoder.layer.9.attention.output.dense.weight
 (768, 768)" fillcolor=lightblue]
	1638868474992 -> 1638912641008
	1638912641008 [label=AccumulateGrad]
	1638912640288 -> 1638912640144
	1638912640096 -> 1638912540528
	1638868475184 [label="bert.encoder.layer.9.attention.output.LayerNorm.weight
 (768)" fillcolor=lightblue]
	1638868475184 -> 1638912640096
	1638912640096 [label=AccumulateGrad]
	1638912640048 -> 1638912540528
	1638868475280 [label="bert.encoder.layer.9.attention.output.LayerNorm.bias
 (768)" fillcolor=lightblue]
	1638868475280 -> 1638912640048
	1638912640048 [label=AccumulateGrad]
	1638912639808 -> 1638912639664
	1638912639808 [label=TBackward0]
	1638912640240 -> 1638912639808
	1638868475376 [label="bert.encoder.layer.9.intermediate.dense.weight
 (3072, 768)" fillcolor=lightblue]
	1638868475376 -> 1638912640240
	1638912640240 [label=AccumulateGrad]
	1638912639040 -> 1638912540624
	1638912639040 [label=TBackward0]
	1638912639616 -> 1638912639040
	1638868475568 [label="bert.encoder.layer.9.output.dense.weight
 (768, 3072)" fillcolor=lightblue]
	1638868475568 -> 1638912639616
	1638912639616 [label=AccumulateGrad]
	1638912540528 -> 1638912540384
	1638912540336 -> 1638912537072
	1638868475760 [label="bert.encoder.layer.9.output.LayerNorm.weight
 (768)" fillcolor=lightblue]
	1638868475760 -> 1638912540336
	1638912540336 [label=AccumulateGrad]
	1638912540288 -> 1638912537072
	1638868475856 [label="bert.encoder.layer.9.output.LayerNorm.bias
 (768)" fillcolor=lightblue]
	1638868475856 -> 1638912540288
	1638912540288 [label=AccumulateGrad]
	1638912540048 -> 1638912539808
	1638912540048 [label=TBackward0]
	1638912540480 -> 1638912540048
	1638868475952 [label="bert.encoder.layer.10.attention.self.query.weight
 (768, 768)" fillcolor=lightblue]
	1638868475952 -> 1638912540480
	1638912540480 [label=AccumulateGrad]
	1638912538848 -> 1638912539040
	1638912538848 [label=ReshapeAliasBackward0]
	1638912539472 -> 1638912538848
	1638912539472 [label=ExpandBackward0]
	1638912539760 -> 1638912539472
	1638912539760 [label=TransposeBackward0]
	1638912540432 -> 1638912539760
	1638912540432 [label=PermuteBackward0]
	1638912540144 -> 1638912540432
	1638912540144 [label=ViewBackward0]
	1638912639520 -> 1638912540144
	1638912639520 [label=ViewBackward0]
	1638912639856 -> 1638912639520
	1638912639856 [label=AddmmBackward0]
	1638912640624 -> 1638912639856
	1638868476240 [label="bert.encoder.layer.10.attention.self.key.bias
 (768)" fillcolor=lightblue]
	1638868476240 -> 1638912640624
	1638912640624 [label=AccumulateGrad]
	1638912639424 -> 1638912639856
	1638912639424 [label=ViewBackward0]
	1638912537072 -> 1638912639424
	1638912639232 -> 1638912639856
	1638912639232 [label=TBackward0]
	1638912641200 -> 1638912639232
	1638868476144 [label="bert.encoder.layer.10.attention.self.key.weight
 (768, 768)" fillcolor=lightblue]
	1638868476144 -> 1638912641200
	1638912641200 [label=AccumulateGrad]
	1638912538128 -> 1638912538032
	1638912538128 [label=ReshapeAliasBackward0]
	1638912538560 -> 1638912538128
	1638912538560 [label=ExpandBackward0]
	1638912538896 -> 1638912538560
	1638912538896 [label=PermuteBackward0]
	1638912539184 -> 1638912538896
	1638912539184 [label=ViewBackward0]
	1638912539616 -> 1638912539184
	1638912539616 [label=ViewBackward0]
	1638912539280 -> 1638912539616
	1638912539280 [label=AddmmBackward0]
	1638912538368 -> 1638912539280
	1638868476432 [label="bert.encoder.layer.10.attention.self.value.bias
 (768)" fillcolor=lightblue]
	1638868476432 -> 1638912538368
	1638912538368 [label=AccumulateGrad]
	1638912640192 -> 1638912539280
	1638912640192 [label=ViewBackward0]
	1638912537072 -> 1638912640192
	1638912639088 -> 1638912539280
	1638912639088 [label=TBackward0]
	1638912640864 -> 1638912639088
	1638868476336 [label="bert.encoder.layer.10.attention.self.value.weight
 (768, 768)" fillcolor=lightblue]
	1638868476336 -> 1638912640864
	1638912640864 [label=AccumulateGrad]
	1638912537168 -> 1638912537264
	1638912537168 [label=TBackward0]
	1638912537792 -> 1638912537168
	1638868476528 [label="bert.encoder.layer.10.attention.output.dense.weight
 (768, 768)" fillcolor=lightblue]
	1638868476528 -> 1638912537792
	1638912537792 [label=AccumulateGrad]
	1638912537072 -> 1638912536928
	1638912536880 -> 1638912535824
	1638868476720 [label="bert.encoder.layer.10.attention.output.LayerNorm.weight
 (768)" fillcolor=lightblue]
	1638868476720 -> 1638912536880
	1638912536880 [label=AccumulateGrad]
	1638912536832 -> 1638912535824
	1638868476816 [label="bert.encoder.layer.10.attention.output.LayerNorm.bias
 (768)" fillcolor=lightblue]
	1638868476816 -> 1638912536832
	1638912536832 [label=AccumulateGrad]
	1638912536304 -> 1638912536496
	1638912536304 [label=TBackward0]
	1638912537024 -> 1638912536304
	1638868476912 [label="bert.encoder.layer.10.intermediate.dense.weight
 (3072, 768)" fillcolor=lightblue]
	1638868476912 -> 1638912537024
	1638912537024 [label=AccumulateGrad]
	1638912535920 -> 1638912536016
	1638912535920 [label=TBackward0]
	1638912536448 -> 1638912535920
	1638868477104 [label="bert.encoder.layer.10.output.dense.weight
 (768, 3072)" fillcolor=lightblue]
	1638868477104 -> 1638912536448
	1638912536448 [label=AccumulateGrad]
	1638912535824 -> 1638912535680
	1638912535632 -> 1638912533136
	1638868477296 [label="bert.encoder.layer.10.output.LayerNorm.weight
 (768)" fillcolor=lightblue]
	1638868477296 -> 1638912535632
	1638912535632 [label=AccumulateGrad]
	1638912535584 -> 1638912533136
	1638868477392 [label="bert.encoder.layer.10.output.LayerNorm.bias
 (768)" fillcolor=lightblue]
	1638868477392 -> 1638912535584
	1638912535584 [label=AccumulateGrad]
	1638912534864 -> 1638912535344
	1638912534864 [label=TBackward0]
	1638912535776 -> 1638912534864
	1638868477488 [label="bert.encoder.layer.11.attention.self.query.weight
 (768, 768)" fillcolor=lightblue]
	1638868477488 -> 1638912535776
	1638912535776 [label=AccumulateGrad]
	1638912534768 -> 1638912534720
	1638912534768 [label=ReshapeAliasBackward0]
	1638912535104 -> 1638912534768
	1638912535104 [label=ExpandBackward0]
	1638912535296 -> 1638912535104
	1638912535296 [label=TransposeBackward0]
	1638912535728 -> 1638912535296
	1638912535728 [label=PermuteBackward0]
	1638912535968 -> 1638912535728
	1638912535968 [label=ViewBackward0]
	1638912536352 -> 1638912535968
	1638912536352 [label=ViewBackward0]
	1638912536640 -> 1638912536352
	1638912536640 [label=AddmmBackward0]
	1638912537408 -> 1638912536640
	1638868477776 [label="bert.encoder.layer.11.attention.self.key.bias
 (768)" fillcolor=lightblue]
	1638868477776 -> 1638912537408
	1638912537408 [label=AccumulateGrad]
	1638912536256 -> 1638912536640
	1638912536256 [label=ViewBackward0]
	1638912533136 -> 1638912536256
	1638912534912 -> 1638912536640
	1638912534912 [label=TBackward0]
	1638912537984 -> 1638912534912
	1638868477680 [label="bert.encoder.layer.11.attention.self.key.weight
 (768, 768)" fillcolor=lightblue]
	1638868477680 -> 1638912537984
	1638912537984 [label=AccumulateGrad]
	1638912534048 -> 1638912534000
	1638912534048 [label=ReshapeAliasBackward0]
	1638912534384 -> 1638912534048
	1638912534384 [label=ExpandBackward0]
	1638912534576 -> 1638912534384
	1638912534576 [label=PermuteBackward0]
	1638912534144 -> 1638912534576
	1638912534144 [label=ViewBackward0]
	1638912535200 -> 1638912534144
	1638912535200 [label=ViewBackward0]
	1638912536160 -> 1638912535200
	1638912536160 [label=AddmmBackward0]
	1638912536976 -> 1638912536160
	1638868477968 [label="bert.encoder.layer.11.attention.self.value.bias
 (768)" fillcolor=lightblue]
	1638868477968 -> 1638912536976
	1638912536976 [label=AccumulateGrad]
	1638912535536 -> 1638912536160
	1638912535536 [label=ViewBackward0]
	1638912533136 -> 1638912535536
	1638912534192 -> 1638912536160
	1638912534192 [label=TBackward0]
	1638912537648 -> 1638912534192
	1638868477872 [label="bert.encoder.layer.11.attention.self.value.weight
 (768, 768)" fillcolor=lightblue]
	1638868477872 -> 1638912537648
	1638912537648 [label=AccumulateGrad]
	1638912533232 -> 1638912533328
	1638912533232 [label=TBackward0]
	1638912533760 -> 1638912533232
	1638868478064 [label="bert.encoder.layer.11.attention.output.dense.weight
 (768, 768)" fillcolor=lightblue]
	1638868478064 -> 1638912533760
	1638912533760 [label=AccumulateGrad]
	1638912533136 -> 1638912532992
	1638912532944 -> 1638912531744
	1638868478256 [label="bert.encoder.layer.11.attention.output.LayerNorm.weight
 (768)" fillcolor=lightblue]
	1638868478256 -> 1638912532944
	1638912532944 [label=AccumulateGrad]
	1638912532896 -> 1638912531744
	1638868478352 [label="bert.encoder.layer.11.attention.output.LayerNorm.bias
 (768)" fillcolor=lightblue]
	1638868478352 -> 1638912532896
	1638912532896 [label=AccumulateGrad]
	1638912532464 -> 1638912532656
	1638912532464 [label=TBackward0]
	1638912533088 -> 1638912532464
	1638868478448 [label="bert.encoder.layer.11.intermediate.dense.weight
 (3072, 768)" fillcolor=lightblue]
	1638868478448 -> 1638912533088
	1638912533088 [label=AccumulateGrad]
	1638912532080 -> 1638912532176
	1638912532080 [label=TBackward0]
	1638912532608 -> 1638912532080
	1638868478640 [label="bert.encoder.layer.11.output.dense.weight
 (768, 3072)" fillcolor=lightblue]
	1638868478640 -> 1638912532608
	1638912532608 [label=AccumulateGrad]
	1638912531744 -> 1638912531840
	1638912531888 -> 1638912531696
	1638868478832 [label="bert.encoder.layer.11.output.LayerNorm.weight
 (768)" fillcolor=lightblue]
	1638868478832 -> 1638912531888
	1638912531888 [label=AccumulateGrad]
	1638912531936 -> 1638912531696
	1638868478928 [label="bert.encoder.layer.11.output.LayerNorm.bias
 (768)" fillcolor=lightblue]
	1638868478928 -> 1638912531936
	1638912531936 [label=AccumulateGrad]
	1638912531696 -> 1638912474000
}
